{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMYpbdbWT/uygAcv+mrINPo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anhphong22/ML_Implementation/blob/master/Homework_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AayQWx-XuEDw",
        "outputId": "99eb1056-a244-4f15-ca50-885d14b6c7c8"
      },
      "source": [
        "#connect gdrive into google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/ML')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/ML; to attempt to forcibly remount, call drive.mount(\"/content/ML\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NaNMrJQuIsp"
      },
      "source": [
        "# import prerequisite libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJyl5XGbyASU"
      },
      "source": [
        "#**1. Data processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRerNQkBxj5e"
      },
      "source": [
        "\"\"\"\n",
        "data_url = https://www.openintro.org/stat/data/ames.csv\n",
        "Read data from csv file\n",
        "Features: Gr.Liv .Area, Bedroom.AbvGr (where Ms.SubClass = 60 & Yr.Sold = 2009)\n",
        "Ground truth: SalePrice\n",
        "\"\"\"\n",
        "\n",
        "data_path = '/content/ML/MyDrive/Dataset/ames.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "data = data.loc[(data['MS.SubClass']==60) & (data['Yr.Sold'] == 2009), ['Gr.Liv.Area', 'Bedroom.AbvGr', 'SalePrice']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEe_G8iq1FNK"
      },
      "source": [
        "\"\"\"\n",
        "Check whether any value in data is null\n",
        "return {False, True}\n",
        "\"\"\"\n",
        "data.isnull().values.any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8Ks9VctBuac"
      },
      "source": [
        "## Feature scaling\n",
        "Get every feature into approximately a $-1 \\le x_{i} \\le 1$ range"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wCMtdtvTSdx"
      },
      "source": [
        "df_pre = data.copy()\n",
        "columns= ['Gr.Liv.Area', 'Bedroom.AbvGr', 'SalePrice']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgiPGRGmoZ1T"
      },
      "source": [
        "# Min Max Scaler\n",
        "scaler = MinMaxScaler()\n",
        "data_scaling = scaler.fit_transform(data[columns])\n",
        "df_min_max = pd.DataFrame(data_scaling, columns = columns)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hevicPqh51uz"
      },
      "source": [
        "# Standard Scaler\n",
        "scaler = StandardScaler()\n",
        "data_scaling = scaler.fit_transform(data[columns])\n",
        "df_std = pd.DataFrame(data_scaling, columns = columns)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "WcYnp_ckBatG",
        "outputId": "9ce2a51f-c13e-472e-f418-bd4b29801e92"
      },
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize= (15, 5))\n",
        "\n",
        "# Original Data\n",
        "sns.boxplot(ax = axes[0], data= df_pre)\n",
        "axes[0].set_title('Original Data')\n",
        "\n",
        "# Minmaxscaler\n",
        "sns.boxplot(ax = axes[1], data= df_min_max)\n",
        "axes[1].set_title('MinMaxScaler')\n",
        "\n",
        "# StandardScaler\n",
        "sns.boxplot(ax = axes[2], data= df_std)\n",
        "axes[2].set_title('StandardScaler')\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KX3b4XTkE9_3"
      },
      "source": [
        "From StandardScaler boxplot, the features are now more comparable and will have a similar effect on the learning models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "o54JbdTyzE57",
        "outputId": "9373262d-b406-4333-e0b6-6e7789b7a3a2"
      },
      "source": [
        "\"\"\"\n",
        "plot the house price versus living area in the form of scattering dots\n",
        "\"\"\"\n",
        "plt.scatter(data['Gr.Liv.Area']/1000, data['SalePrice']/100000, c = 'b')\n",
        "plt.xlabel('Living area 1000 sq.ft')\n",
        "plt.ylabel('Price $100,000')\n",
        "plt.title('The sale price versus living area')\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhI3n-HP1za8"
      },
      "source": [
        "# **2. Compute weights and loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTQIp7oO1zEm"
      },
      "source": [
        "\"\"\"\n",
        "Split the data into 2 parts:\n",
        "- Training data: 70%\n",
        "- Testing data: 30%\n",
        "\"\"\"\n",
        "df_pre = df_std\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_pre.drop(columns= ['SalePrice']), df_pre.SalePrice, test_size = 0.3, random_state = 42 )"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws7MPexJ36l_"
      },
      "source": [
        "##2.1 Closed form"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGbD0hfW4trC"
      },
      "source": [
        "# add bias for dataset\n",
        "X_train_bias = np.c_[np.ones(X_train.shape[0]), X_train]\n",
        "X_test_bias = np.c_[np.ones(X_test.shape[0]), X_test]\n",
        "#y_tr = np.array(y_train)\n",
        "#y_te = np.array(y_test)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taUENxLS4Nmh"
      },
      "source": [
        "  def closed_form(X, y):\n",
        "    A = np.dot(X.T, X)\n",
        "    b = np.dot(X.T, y)\n",
        "    w = np.dot(np.linalg.pinv(A), b)\n",
        "    return w"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDf9dU-96Ebt"
      },
      "source": [
        "cf = closed_form(X_train_bias, y_train)\n",
        "w = np.array(cf)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXKP5gkOMjbj",
        "outputId": "8fed0b2f-c777-4308-8b86-6eaa17fee37d"
      },
      "source": [
        "w"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.04107696,  0.81430085, -0.17990706])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN3FcKfi-msk"
      },
      "source": [
        "##2.2 Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeLZ2VkmFmQC"
      },
      "source": [
        "\"\"\"\n",
        "functions: compute loss and gradient\n",
        "\"\"\"\n",
        "\n",
        "def loss(X, y, w):\n",
        "  y_p = X.dot(w)\n",
        "  h = y_p - y\n",
        "  return 0.5*np.mean(np.dot(h.T, h))\n",
        "\n",
        "def grad(X, y, w):\n",
        "  n = X.shape[0]\n",
        "  y_p = X.dot(w)\n",
        "  h = y_p - y\n",
        "  return 1/n * np.dot(X.T, h)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXD_S-lvXa_9"
      },
      "source": [
        "def gradient_descent(w, X_train, X_test, y_train, y_test, lr, epochs):\n",
        "  log = {\"train_loss\":[],\n",
        "         \"weights\":[],\n",
        "         \"test_loss\":[] \n",
        "  }\n",
        "  for i in range(1, epochs + 1):\n",
        "    # training loss\n",
        "    train_loss = loss(X_train, y_train, w)\n",
        "    log[\"train_loss\"].append(train_loss)\n",
        "\n",
        "    #gradient descent\n",
        "    dw = grad(X_train, y_train, w)\n",
        "    w = w - lr* dw\n",
        "    log[\"weights\"].append(w)\n",
        "\n",
        "    # testing loss\n",
        "    test_loss = loss(X_test, y_test, w)\n",
        "    log[\"test_loss\"].append(test_loss)\n",
        "\n",
        "    print('--------------------------------')\n",
        "    print(f'Epoch: {i} / {epochs}')\n",
        "    print(f'Train_loss: {train_loss}')\n",
        "    print(f'Test_loss: {test_loss}')\n",
        "    print(f'Weights: {w.flatten()}')\n",
        "  \n",
        "  return log"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu9sR3_lV8u4",
        "outputId": "6f9d925b-c6a3-45b1-d4a2-8a70ba07be11"
      },
      "source": [
        "# initial data\n",
        "w = np.zeros((X_train_bias.shape[1], 1))\n",
        "y_tr = np.array([y_train]).T\n",
        "y_te = np.array([y_test]).T\n",
        "\n",
        "# compute loss, weights\n",
        "log = gradient_descent(w, X_train_bias, X_test_bias, y_tr, y_te, lr= 0.1, epochs= 500)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Epoch: 1 / 500\n",
            "Train_loss: 37.469418836502165\n",
            "Test_loss: 19.922976897125903\n",
            "Weights: [-0.00576074  0.07648297  0.02604934]\n",
            "--------------------------------\n",
            "Epoch: 2 / 500\n",
            "Train_loss: 32.341159980604615\n",
            "Test_loss: 17.93843140330412\n",
            "Weights: [-0.01085006  0.14342399  0.04522737]\n",
            "--------------------------------\n",
            "Epoch: 3 / 500\n",
            "Train_loss: 28.522264416135645\n",
            "Test_loss: 16.41231816294056\n",
            "Weights: [-0.01534193  0.20221201  0.05876474]\n",
            "--------------------------------\n",
            "Epoch: 4 / 500\n",
            "Train_loss: 25.647855700555038\n",
            "Test_loss: 15.225789197371157\n",
            "Weights: [-0.01930227  0.2540212   0.06768916]\n",
            "--------------------------------\n",
            "Epoch: 5 / 500\n",
            "Train_loss: 23.458164622702743\n",
            "Test_loss: 14.292706384363361\n",
            "Weights: [-0.02278982  0.29984485  0.07285811]\n",
            "--------------------------------\n",
            "Epoch: 6 / 500\n",
            "Train_loss: 21.76789592065136\n",
            "Test_loss: 13.550354458755956\n",
            "Weights: [-0.02585693  0.34052391  0.07498631]\n",
            "--------------------------------\n",
            "Epoch: 7 / 500\n",
            "Train_loss: 20.44455940035899\n",
            "Test_loss: 12.952833750624514\n",
            "Weights: [-0.02855025  0.37677092  0.07466873]\n",
            "--------------------------------\n",
            "Epoch: 8 / 500\n",
            "Train_loss: 19.393138345198885\n",
            "Test_loss: 12.466352949159528\n",
            "Weights: [-0.03091138  0.40919023  0.07240002]\n",
            "--------------------------------\n",
            "Epoch: 9 / 500\n",
            "Train_loss: 18.545238426703214\n",
            "Test_loss: 12.06587001963666\n",
            "Weights: [-0.03297741  0.43829496  0.06859074]\n",
            "--------------------------------\n",
            "Epoch: 10 / 500\n",
            "Train_loss: 17.851404724036307\n",
            "Test_loss: 11.732690520308765\n",
            "Weights: [-0.03478141  0.46452129  0.06358105]\n",
            "--------------------------------\n",
            "Epoch: 11 / 500\n",
            "Train_loss: 17.275679200225984\n",
            "Test_loss: 11.452746524331047\n",
            "Weights: [-0.03635287  0.48824046  0.05765217]\n",
            "--------------------------------\n",
            "Epoch: 12 / 500\n",
            "Train_loss: 16.79174289558726\n",
            "Test_loss: 11.215359971175284\n",
            "Weights: [-0.03771807  0.50976893  0.05103602]\n",
            "--------------------------------\n",
            "Epoch: 13 / 500\n",
            "Train_loss: 16.380179275616555\n",
            "Test_loss: 11.01235132106396\n",
            "Weights: [-0.03890046  0.52937684  0.04392328]\n",
            "--------------------------------\n",
            "Epoch: 14 / 500\n",
            "Train_loss: 16.02653099770633\n",
            "Test_loss: 10.837394768954214\n",
            "Weights: [-0.03992092  0.54729523  0.03647022]\n",
            "--------------------------------\n",
            "Epoch: 15 / 500\n",
            "Train_loss: 15.719918364674465\n",
            "Test_loss: 10.685549871481976\n",
            "Weights: [-0.04079808  0.56372205  0.02880432]\n",
            "--------------------------------\n",
            "Epoch: 16 / 500\n",
            "Train_loss: 15.45205559230135\n",
            "Test_loss: 10.552919700498407\n",
            "Weights: [-0.04154856  0.57882726  0.02102913]\n",
            "--------------------------------\n",
            "Epoch: 17 / 500\n",
            "Train_loss: 15.216548986299998\n",
            "Test_loss: 10.436399998906829\n",
            "Weights: [-0.04218713  0.59275709  0.0132282 ]\n",
            "--------------------------------\n",
            "Epoch: 18 / 500\n",
            "Train_loss: 15.008395034169185\n",
            "Test_loss: 10.3334940024834\n",
            "Weights: [-0.04272698  0.60563768  0.00546849]\n",
            "--------------------------------\n",
            "Epoch: 19 / 500\n",
            "Train_loss: 14.823620391275803\n",
            "Test_loss: 10.242174824314048\n",
            "Weights: [-0.04317984  0.61757812 -0.00219686]\n",
            "--------------------------------\n",
            "Epoch: 20 / 500\n",
            "Train_loss: 14.65902269144681\n",
            "Test_loss: 10.160782438562372\n",
            "Weights: [-0.04355616  0.62867299 -0.00972614]\n",
            "--------------------------------\n",
            "Epoch: 21 / 500\n",
            "Train_loss: 14.511983099161126\n",
            "Test_loss: 10.087945957361834\n",
            "Weights: [-0.04386524  0.63900455 -0.01708712]\n",
            "--------------------------------\n",
            "Epoch: 22 / 500\n",
            "Train_loss: 14.380329998201812\n",
            "Test_loss: 10.022524500206778\n",
            "Weights: [-0.04411536  0.64864456 -0.02425538]\n",
            "--------------------------------\n",
            "Epoch: 23 / 500\n",
            "Train_loss: 14.262239208766134\n",
            "Test_loss: 9.963561814706233\n",
            "Weights: [-0.04431387  0.65765583 -0.03121296]\n",
            "--------------------------------\n",
            "Epoch: 24 / 500\n",
            "Train_loss: 14.156160368403844\n",
            "Test_loss: 9.910251137195662\n",
            "Weights: [-0.04446731  0.66609351 -0.03794716]\n",
            "--------------------------------\n",
            "Epoch: 25 / 500\n",
            "Train_loss: 14.060762115524163\n",
            "Test_loss: 9.861907734644028\n",
            "Weights: [-0.04458148  0.67400621 -0.04444962]\n",
            "--------------------------------\n",
            "Epoch: 26 / 500\n",
            "Train_loss: 13.974890840729893\n",
            "Test_loss: 9.817947254102208\n",
            "Weights: [-0.04466154  0.6814369  -0.05071551]\n",
            "--------------------------------\n",
            "Epoch: 27 / 500\n",
            "Train_loss: 13.897539277609122\n",
            "Test_loss: 9.777868499599538\n",
            "Weights: [-0.04471206  0.68842375 -0.05674281]\n",
            "--------------------------------\n",
            "Epoch: 28 / 500\n",
            "Train_loss: 13.82782227231352\n",
            "Test_loss: 9.741239613551084\n",
            "Weights: [-0.04473709  0.69500074 -0.06253184]\n",
            "--------------------------------\n",
            "Epoch: 29 / 500\n",
            "Train_loss: 13.76495782857603\n",
            "Test_loss: 9.707686899206356\n",
            "Weights: [-0.04474022  0.70119828 -0.06808471]\n",
            "--------------------------------\n",
            "Epoch: 30 / 500\n",
            "Train_loss: 13.708252062483597\n",
            "Test_loss: 9.676885710060123\n",
            "Weights: [-0.04472462  0.70704367 -0.07340499]\n",
            "--------------------------------\n",
            "Epoch: 31 / 500\n",
            "Train_loss: 13.657087083469047\n",
            "Test_loss: 9.648552971119338\n",
            "Weights: [-0.04469309  0.71256148 -0.07849738]\n",
            "--------------------------------\n",
            "Epoch: 32 / 500\n",
            "Train_loss: 13.610911089987296\n",
            "Test_loss: 9.622440999503203\n",
            "Weights: [-0.04464811  0.71777397 -0.08336742]\n",
            "--------------------------------\n",
            "Epoch: 33 / 500\n",
            "Train_loss: 13.56923016228498\n",
            "Test_loss: 9.598332368068288\n",
            "Weights: [-0.04459186  0.72270131 -0.08802132]\n",
            "--------------------------------\n",
            "Epoch: 34 / 500\n",
            "Train_loss: 13.531601373263728\n",
            "Test_loss: 9.57603561277813\n",
            "Weights: [-0.04452626  0.72736188 -0.09246573]\n",
            "--------------------------------\n",
            "Epoch: 35 / 500\n",
            "Train_loss: 13.497626937743243\n",
            "Test_loss: 9.555381627530856\n",
            "Weights: [-0.04445299  0.73177247 -0.09670764]\n",
            "--------------------------------\n",
            "Epoch: 36 / 500\n",
            "Train_loss: 13.466949191825881\n",
            "Test_loss: 9.536220622833765\n",
            "Weights: [-0.04437354  0.73594849 -0.10075423]\n",
            "--------------------------------\n",
            "Epoch: 37 / 500\n",
            "Train_loss: 13.439246245604988\n",
            "Test_loss: 9.518419549753931\n",
            "Weights: [-0.0442892   0.73990407 -0.10461276]\n",
            "--------------------------------\n",
            "Epoch: 38 / 500\n",
            "Train_loss: 13.414228189852965\n",
            "Test_loss: 9.501859909926898\n",
            "Weights: [-0.04420111  0.74365228 -0.10829056]\n",
            "--------------------------------\n",
            "Epoch: 39 / 500\n",
            "Train_loss: 13.391633764618613\n",
            "Test_loss: 9.486435887491789\n",
            "Weights: [-0.04411023  0.74720519 -0.11179488]\n",
            "--------------------------------\n",
            "Epoch: 40 / 500\n",
            "Train_loss: 13.371227417728235\n",
            "Test_loss: 9.472052750680907\n",
            "Weights: [-0.04401744  0.75057397 -0.11513291]\n",
            "--------------------------------\n",
            "Epoch: 41 / 500\n",
            "Train_loss: 13.352796696060741\n",
            "Test_loss: 9.458625480192966\n",
            "Weights: [-0.04392347  0.75376902 -0.11831168]\n",
            "--------------------------------\n",
            "Epoch: 42 / 500\n",
            "Train_loss: 13.336149923603404\n",
            "Test_loss: 9.446077588989683\n",
            "Weights: [-0.04382897  0.75680002 -0.1213381 ]\n",
            "--------------------------------\n",
            "Epoch: 43 / 500\n",
            "Train_loss: 13.321114128724757\n",
            "Test_loss: 9.43434010420121\n",
            "Weights: [-0.04373447  0.75967599 -0.12421887]\n",
            "--------------------------------\n",
            "Epoch: 44 / 500\n",
            "Train_loss: 13.307533189561086\n",
            "Test_loss: 9.42335068672623\n",
            "Weights: [-0.04364045  0.76240538 -0.12696051]\n",
            "--------------------------------\n",
            "Epoch: 45 / 500\n",
            "Train_loss: 13.295266171429482\n",
            "Test_loss: 9.413052868110023\n",
            "Weights: [-0.04354731  0.76499608 -0.12956932]\n",
            "--------------------------------\n",
            "Epoch: 46 / 500\n",
            "Train_loss: 13.284185834131518\n",
            "Test_loss: 9.403395387564062\n",
            "Weights: [-0.04345539  0.76745551 -0.13205139]\n",
            "--------------------------------\n",
            "Epoch: 47 / 500\n",
            "Train_loss: 13.274177290168543\n",
            "Test_loss: 9.394331614696608\n",
            "Weights: [-0.04336496  0.76979061 -0.13441258]\n",
            "--------------------------------\n",
            "Epoch: 48 / 500\n",
            "Train_loss: 13.265136797448921\n",
            "Test_loss: 9.385819045766258\n",
            "Weights: [-0.04327626  0.77200794 -0.13665854]\n",
            "--------------------------------\n",
            "Epoch: 49 / 500\n",
            "Train_loss: 13.25697067217159\n",
            "Test_loss: 9.377818863137142\n",
            "Weights: [-0.04318948  0.77411365 -0.13879468]\n",
            "--------------------------------\n",
            "Epoch: 50 / 500\n",
            "Train_loss: 13.249594309323264\n",
            "Test_loss: 9.370295549174028\n",
            "Weights: [-0.04310477  0.77611354 -0.1408262 ]\n",
            "--------------------------------\n",
            "Epoch: 51 / 500\n",
            "Train_loss: 13.242931299704892\n",
            "Test_loss: 9.363216547122732\n",
            "Weights: [-0.04302225  0.77801308 -0.14275808]\n",
            "--------------------------------\n",
            "Epoch: 52 / 500\n",
            "Train_loss: 13.236912633663458\n",
            "Test_loss: 9.356551962620534\n",
            "Weights: [-0.04294202  0.77981743 -0.14459508]\n",
            "--------------------------------\n",
            "Epoch: 53 / 500\n",
            "Train_loss: 13.231475982790652\n",
            "Test_loss: 9.350274300407856\n",
            "Weights: [-0.04286415  0.78153148 -0.14634177]\n",
            "--------------------------------\n",
            "Epoch: 54 / 500\n",
            "Train_loss: 13.226565051791985\n",
            "Test_loss: 9.344358231595393\n",
            "Weights: [-0.04278867  0.78315984 -0.1480025 ]\n",
            "--------------------------------\n",
            "Epoch: 55 / 500\n",
            "Train_loss: 13.22212899355389\n",
            "Test_loss: 9.338780387504096\n",
            "Weights: [-0.04271562  0.78470687 -0.14958142]\n",
            "--------------------------------\n",
            "Epoch: 56 / 500\n",
            "Train_loss: 13.218121881161219\n",
            "Test_loss: 9.333519176657903\n",
            "Weights: [-0.04264501  0.78617669 -0.15108252]\n",
            "--------------------------------\n",
            "Epoch: 57 / 500\n",
            "Train_loss: 13.214502231258042\n",
            "Test_loss: 9.328554621987522\n",
            "Weights: [-0.04257684  0.78757321 -0.15250956]\n",
            "--------------------------------\n",
            "Epoch: 58 / 500\n",
            "Train_loss: 13.211232573713495\n",
            "Test_loss: 9.323868215710707\n",
            "Weights: [-0.04251109  0.78890014 -0.15386617]\n",
            "--------------------------------\n",
            "Epoch: 59 / 500\n",
            "Train_loss: 13.208279063060843\n",
            "Test_loss: 9.319442789701855\n",
            "Weights: [-0.04244774  0.79016098 -0.15515579]\n",
            "--------------------------------\n",
            "Epoch: 60 / 500\n",
            "Train_loss: 13.205611127630295\n",
            "Test_loss: 9.315262399460353\n",
            "Weights: [-0.04238675  0.79135905 -0.15638169]\n",
            "--------------------------------\n",
            "Epoch: 61 / 500\n",
            "Train_loss: 13.20320115270073\n",
            "Test_loss: 9.311312220040898\n",
            "Weights: [-0.04232809  0.79249752 -0.157547  ]\n",
            "--------------------------------\n",
            "Epoch: 62 / 500\n",
            "Train_loss: 13.20102419435868\n",
            "Test_loss: 9.30757845252634\n",
            "Weights: [-0.0422717   0.79357936 -0.15865469]\n",
            "--------------------------------\n",
            "Epoch: 63 / 500\n",
            "Train_loss: 13.199057721078423\n",
            "Test_loss: 9.304048239810083\n",
            "Weights: [-0.04221755  0.79460742 -0.15970759]\n",
            "--------------------------------\n",
            "Epoch: 64 / 500\n",
            "Train_loss: 13.197281380330205\n",
            "Test_loss: 9.300709590615256\n",
            "Weights: [-0.04216558  0.79558438 -0.1607084 ]\n",
            "--------------------------------\n",
            "Epoch: 65 / 500\n",
            "Train_loss: 13.195676787786931\n",
            "Test_loss: 9.297551310815622\n",
            "Weights: [-0.04211572  0.7965128  -0.16165969]\n",
            "--------------------------------\n",
            "Epoch: 66 / 500\n",
            "Train_loss: 13.194227336936912\n",
            "Test_loss: 9.294562941241876\n",
            "Weights: [-0.04206793  0.7973951  -0.16256389]\n",
            "--------------------------------\n",
            "Epoch: 67 / 500\n",
            "Train_loss: 13.192918027124081\n",
            "Test_loss: 9.29173470125939\n",
            "Weights: [-0.04202213  0.79823358 -0.16342333]\n",
            "--------------------------------\n",
            "Epoch: 68 / 500\n",
            "Train_loss: 13.191735308229582\n",
            "Test_loss: 9.289057437491929\n",
            "Weights: [-0.04197827  0.79903043 -0.16424021]\n",
            "--------------------------------\n",
            "Epoch: 69 / 500\n",
            "Train_loss: 13.190666940382407\n",
            "Test_loss: 9.286522577142302\n",
            "Weights: [-0.04193629  0.79978772 -0.16501664]\n",
            "--------------------------------\n",
            "Epoch: 70 / 500\n",
            "Train_loss: 13.189701867243352\n",
            "Test_loss: 9.284122085427324\n",
            "Weights: [-0.04189611  0.80050742 -0.16575462]\n",
            "--------------------------------\n",
            "Epoch: 71 / 500\n",
            "Train_loss: 13.188830101548\n",
            "Test_loss: 9.281848426701881\n",
            "Weights: [-0.04185769  0.80119141 -0.16645604]\n",
            "--------------------------------\n",
            "Epoch: 72 / 500\n",
            "Train_loss: 13.188042621721737\n",
            "Test_loss: 9.279694528897014\n",
            "Weights: [-0.04182095  0.80184145 -0.16712271]\n",
            "--------------------------------\n",
            "Epoch: 73 / 500\n",
            "Train_loss: 13.187331278495252\n",
            "Test_loss: 9.277653750940335\n",
            "Weights: [-0.04178584  0.80245924 -0.16775636]\n",
            "--------------------------------\n",
            "Epoch: 74 / 500\n",
            "Train_loss: 13.18668871055248\n",
            "Test_loss: 9.275719852865112\n",
            "Weights: [-0.04175229  0.80304638 -0.16835861]\n",
            "--------------------------------\n",
            "Epoch: 75 / 500\n",
            "Train_loss: 13.186108268336978\n",
            "Test_loss: 9.273886968347515\n",
            "Weights: [-0.04172024  0.80360439 -0.16893102]\n",
            "--------------------------------\n",
            "Epoch: 76 / 500\n",
            "Train_loss: 13.18558394522743\n",
            "Test_loss: 9.272149579440393\n",
            "Weights: [-0.04168964  0.80413473 -0.16947506]\n",
            "--------------------------------\n",
            "Epoch: 77 / 500\n",
            "Train_loss: 13.185110315369133\n",
            "Test_loss: 9.27050249329743\n",
            "Weights: [-0.04166043  0.80463876 -0.16999215]\n",
            "--------------------------------\n",
            "Epoch: 78 / 500\n",
            "Train_loss: 13.184682477517732\n",
            "Test_loss: 9.268940820703833\n",
            "Weights: [-0.04163255  0.80511779 -0.17048361]\n",
            "--------------------------------\n",
            "Epoch: 79 / 500\n",
            "Train_loss: 13.184296004313508\n",
            "Test_loss: 9.267459956249128\n",
            "Weights: [-0.04160595  0.80557306 -0.17095071]\n",
            "--------------------------------\n",
            "Epoch: 80 / 500\n",
            "Train_loss: 13.183946896460965\n",
            "Test_loss: 9.266055559995179\n",
            "Weights: [-0.04158057  0.80600576 -0.17139466]\n",
            "--------------------------------\n",
            "Epoch: 81 / 500\n",
            "Train_loss: 13.183631541339242\n",
            "Test_loss: 9.264723540507365\n",
            "Weights: [-0.04155636  0.80641699 -0.17181661]\n",
            "--------------------------------\n",
            "Epoch: 82 / 500\n",
            "Train_loss: 13.183346675614844\n",
            "Test_loss: 9.263460039130747\n",
            "Weights: [-0.04153328  0.80680784 -0.17221765]\n",
            "--------------------------------\n",
            "Epoch: 83 / 500\n",
            "Train_loss: 13.183089351469585\n",
            "Test_loss: 9.262261415404478\n",
            "Weights: [-0.04151128  0.80717931 -0.17259881]\n",
            "--------------------------------\n",
            "Epoch: 84 / 500\n",
            "Train_loss: 13.18285690609408\n",
            "Test_loss: 9.261124233518656\n",
            "Weights: [-0.0414903   0.80753235 -0.17296107]\n",
            "--------------------------------\n",
            "Epoch: 85 / 500\n",
            "Train_loss: 13.182646934131059\n",
            "Test_loss: 9.260045249726947\n",
            "Weights: [-0.04147031  0.80786789 -0.17330538]\n",
            "--------------------------------\n",
            "Epoch: 86 / 500\n",
            "Train_loss: 13.182457262783187\n",
            "Test_loss: 9.259021400636682\n",
            "Weights: [-0.04145126  0.8081868  -0.17363263]\n",
            "--------------------------------\n",
            "Epoch: 87 / 500\n",
            "Train_loss: 13.18228592932771\n",
            "Test_loss: 9.258049792305606\n",
            "Weights: [-0.04143311  0.80848989 -0.17394365]\n",
            "--------------------------------\n",
            "Epoch: 88 / 500\n",
            "Train_loss: 13.182131160805262\n",
            "Test_loss: 9.257127690081017\n",
            "Weights: [-0.04141582  0.80877796 -0.17423926]\n",
            "--------------------------------\n",
            "Epoch: 89 / 500\n",
            "Train_loss: 13.18199135567251\n",
            "Test_loss: 9.256252509122977\n",
            "Weights: [-0.04139935  0.80905174 -0.17452021]\n",
            "--------------------------------\n",
            "Epoch: 90 / 500\n",
            "Train_loss: 13.181865067228788\n",
            "Test_loss: 9.255421805558573\n",
            "Weights: [-0.04138366  0.80931196 -0.17478724]\n",
            "--------------------------------\n",
            "Epoch: 91 / 500\n",
            "Train_loss: 13.181750988645188\n",
            "Test_loss: 9.254633268218948\n",
            "Weights: [-0.04136872  0.80955927 -0.17504103]\n",
            "--------------------------------\n",
            "Epoch: 92 / 500\n",
            "Train_loss: 13.181647939441136\n",
            "Test_loss: 9.253884710915099\n",
            "Weights: [-0.0413545   0.80979432 -0.17528224]\n",
            "--------------------------------\n",
            "Epoch: 93 / 500\n",
            "Train_loss: 13.18155485326851\n",
            "Test_loss: 9.253174065212258\n",
            "Weights: [-0.04134095  0.81001771 -0.1755115 ]\n",
            "--------------------------------\n",
            "Epoch: 94 / 500\n",
            "Train_loss: 13.181470766876847\n",
            "Test_loss: 9.252499373666156\n",
            "Weights: [-0.04132806  0.81023003 -0.17572939]\n",
            "--------------------------------\n",
            "Epoch: 95 / 500\n",
            "Train_loss: 13.181394810145486\n",
            "Test_loss: 9.251858783487497\n",
            "Weights: [-0.04131579  0.81043183 -0.17593647]\n",
            "--------------------------------\n",
            "Epoch: 96 / 500\n",
            "Train_loss: 13.181326197079432\n",
            "Test_loss: 9.251250540603982\n",
            "Weights: [-0.0413041   0.81062362 -0.1761333 ]\n",
            "--------------------------------\n",
            "Epoch: 97 / 500\n",
            "Train_loss: 13.18126421767582\n",
            "Test_loss: 9.250672984091484\n",
            "Weights: [-0.04129298  0.81080591 -0.17632036]\n",
            "--------------------------------\n",
            "Epoch: 98 / 500\n",
            "Train_loss: 13.181208230576708\n",
            "Test_loss: 9.250124540948569\n",
            "Weights: [-0.0412824   0.81097916 -0.17649816]\n",
            "--------------------------------\n",
            "Epoch: 99 / 500\n",
            "Train_loss: 13.181157656432307\n",
            "Test_loss: 9.249603721190395\n",
            "Weights: [-0.04127233  0.81114381 -0.17666714]\n",
            "--------------------------------\n",
            "Epoch: 100 / 500\n",
            "Train_loss: 13.181111971905827\n",
            "Test_loss: 9.249109113240138\n",
            "Weights: [-0.04126275  0.81130031 -0.17682774]\n",
            "--------------------------------\n",
            "Epoch: 101 / 500\n",
            "Train_loss: 13.181070704257962\n",
            "Test_loss: 9.248639379597654\n",
            "Weights: [-0.04125363  0.81144905 -0.17698039]\n",
            "--------------------------------\n",
            "Epoch: 102 / 500\n",
            "Train_loss: 13.181033426455006\n",
            "Test_loss: 9.248193252766752\n",
            "Weights: [-0.04124496  0.81159042 -0.17712546]\n",
            "--------------------------------\n",
            "Epoch: 103 / 500\n",
            "Train_loss: 13.180999752749885\n",
            "Test_loss: 9.247769531423842\n",
            "Weights: [-0.0412367   0.81172477 -0.17726335]\n",
            "--------------------------------\n",
            "Epoch: 104 / 500\n",
            "Train_loss: 13.180969334690465\n",
            "Test_loss: 9.247367076812038\n",
            "Weights: [-0.04122885  0.81185247 -0.1773944 ]\n",
            "--------------------------------\n",
            "Epoch: 105 / 500\n",
            "Train_loss: 13.18094185751379\n",
            "Test_loss: 9.246984809346035\n",
            "Weights: [-0.04122138  0.81197384 -0.17751895]\n",
            "--------------------------------\n",
            "Epoch: 106 / 500\n",
            "Train_loss: 13.180917036888893\n",
            "Test_loss: 9.24662170541404\n",
            "Weights: [-0.04121428  0.81208919 -0.17763733]\n",
            "--------------------------------\n",
            "Epoch: 107 / 500\n",
            "Train_loss: 13.18089461597459\n",
            "Test_loss: 9.24627679436424\n",
            "Weights: [-0.04120752  0.81219882 -0.17774984]\n",
            "--------------------------------\n",
            "Epoch: 108 / 500\n",
            "Train_loss: 13.180874362761674\n",
            "Test_loss: 9.245949155663984\n",
            "Weights: [-0.04120109  0.81230302 -0.17785677]\n",
            "--------------------------------\n",
            "Epoch: 109 / 500\n",
            "Train_loss: 13.180856067672112\n",
            "Test_loss: 9.24563791622088\n",
            "Weights: [-0.04119498  0.81240205 -0.17795841]\n",
            "--------------------------------\n",
            "Epoch: 110 / 500\n",
            "Train_loss: 13.180839541390347\n",
            "Test_loss: 9.245342247855643\n",
            "Weights: [-0.04118916  0.81249618 -0.178055  ]\n",
            "--------------------------------\n",
            "Epoch: 111 / 500\n",
            "Train_loss: 13.180824612904255\n",
            "Test_loss: 9.245061364917373\n",
            "Weights: [-0.04118363  0.81258563 -0.17814681]\n",
            "--------------------------------\n",
            "Epoch: 112 / 500\n",
            "Train_loss: 13.18081112773555\n",
            "Test_loss: 9.244794522032434\n",
            "Weights: [-0.04117838  0.81267066 -0.17823407]\n",
            "--------------------------------\n",
            "Epoch: 113 / 500\n",
            "Train_loss: 13.18079894634124\n",
            "Test_loss: 9.244541011978853\n",
            "Weights: [-0.04117337  0.81275147 -0.178317  ]\n",
            "--------------------------------\n",
            "Epoch: 114 / 500\n",
            "Train_loss: 13.180787942669655\n",
            "Test_loss: 9.244300163678655\n",
            "Weights: [-0.04116862  0.81282827 -0.17839582]\n",
            "--------------------------------\n",
            "Epoch: 115 / 500\n",
            "Train_loss: 13.180778002856075\n",
            "Test_loss: 9.244071340301009\n",
            "Weights: [-0.0411641   0.81290126 -0.17847073]\n",
            "--------------------------------\n",
            "Epoch: 116 / 500\n",
            "Train_loss: 13.180769024044451\n",
            "Test_loss: 9.243853937469634\n",
            "Weights: [-0.04115979  0.81297064 -0.17854193]\n",
            "--------------------------------\n",
            "Epoch: 117 / 500\n",
            "Train_loss: 13.180760913323105\n",
            "Test_loss: 9.243647381568282\n",
            "Weights: [-0.04115571  0.81303658 -0.1786096 ]\n",
            "--------------------------------\n",
            "Epoch: 118 / 500\n",
            "Train_loss: 13.180753586763233\n",
            "Test_loss: 9.243451128138522\n",
            "Weights: [-0.04115182  0.81309925 -0.17867391]\n",
            "--------------------------------\n",
            "Epoch: 119 / 500\n",
            "Train_loss: 13.180746968550455\n",
            "Test_loss: 9.243264660364472\n",
            "Weights: [-0.04114812  0.81315881 -0.17873504]\n",
            "--------------------------------\n",
            "Epoch: 120 / 500\n",
            "Train_loss: 13.180740990200295\n",
            "Test_loss: 9.24308748763938\n",
            "Weights: [-0.04114461  0.81321542 -0.17879314]\n",
            "--------------------------------\n",
            "Epoch: 121 / 500\n",
            "Train_loss: 13.180735589849489\n",
            "Test_loss: 9.242919144209441\n",
            "Weights: [-0.04114126  0.81326923 -0.17884835]\n",
            "--------------------------------\n",
            "Epoch: 122 / 500\n",
            "Train_loss: 13.180730711615848\n",
            "Test_loss: 9.242759187890286\n",
            "Weights: [-0.04113809  0.81332036 -0.17890083]\n",
            "--------------------------------\n",
            "Epoch: 123 / 500\n",
            "Train_loss: 13.180726305020002\n",
            "Test_loss: 9.242607198852124\n",
            "Weights: [-0.04113506  0.81336897 -0.17895071]\n",
            "--------------------------------\n",
            "Epoch: 124 / 500\n",
            "Train_loss: 13.18072232446301\n",
            "Test_loss: 9.242462778469605\n",
            "Weights: [-0.04113219  0.81341516 -0.17899812]\n",
            "--------------------------------\n",
            "Epoch: 125 / 500\n",
            "Train_loss: 13.18071872875455\n",
            "Test_loss: 9.242325548232733\n",
            "Weights: [-0.04112946  0.81345906 -0.17904318]\n",
            "--------------------------------\n",
            "Epoch: 126 / 500\n",
            "Train_loss: 13.180715480686672\n",
            "Test_loss: 9.242195148715444\n",
            "Weights: [-0.04112687  0.81350079 -0.179086  ]\n",
            "--------------------------------\n",
            "Epoch: 127 / 500\n",
            "Train_loss: 13.18071254664875\n",
            "Test_loss: 9.242071238598678\n",
            "Weights: [-0.0411244   0.81354045 -0.1791267 ]\n",
            "--------------------------------\n",
            "Epoch: 128 / 500\n",
            "Train_loss: 13.180709896279712\n",
            "Test_loss: 9.24195349374475\n",
            "Weights: [-0.04112205  0.81357814 -0.17916538]\n",
            "--------------------------------\n",
            "Epoch: 129 / 500\n",
            "Train_loss: 13.180707502153872\n",
            "Test_loss: 9.241841606320442\n",
            "Weights: [-0.04111982  0.81361397 -0.17920215]\n",
            "--------------------------------\n",
            "Epoch: 130 / 500\n",
            "Train_loss: 13.180705339497086\n",
            "Test_loss: 9.241735283965912\n",
            "Weights: [-0.0411177   0.81364801 -0.17923709]\n",
            "--------------------------------\n",
            "Epoch: 131 / 500\n",
            "Train_loss: 13.180703385930459\n",
            "Test_loss: 9.241634249007049\n",
            "Weights: [-0.04111568  0.81368037 -0.1792703 ]\n",
            "--------------------------------\n",
            "Epoch: 132 / 500\n",
            "Train_loss: 13.180701621238704\n",
            "Test_loss: 9.241538237708847\n",
            "Weights: [-0.04111377  0.81371113 -0.17930186]\n",
            "--------------------------------\n",
            "Epoch: 133 / 500\n",
            "Train_loss: 13.180700027161024\n",
            "Test_loss: 9.241446999567586\n",
            "Weights: [-0.04111195  0.81374036 -0.17933186]\n",
            "--------------------------------\n",
            "Epoch: 134 / 500\n",
            "Train_loss: 13.180698587202077\n",
            "Test_loss: 9.241360296639757\n",
            "Weights: [-0.04111022  0.81376815 -0.17936038]\n",
            "--------------------------------\n",
            "Epoch: 135 / 500\n",
            "Train_loss: 13.18069728646136\n",
            "Test_loss: 9.241277902905662\n",
            "Weights: [-0.04110857  0.81379455 -0.17938747]\n",
            "--------------------------------\n",
            "Epoch: 136 / 500\n",
            "Train_loss: 13.180696111478953\n",
            "Test_loss: 9.24119960366595\n",
            "Weights: [-0.041107    0.81381965 -0.17941323]\n",
            "--------------------------------\n",
            "Epoch: 137 / 500\n",
            "Train_loss: 13.180695050096286\n",
            "Test_loss: 9.241125194969214\n",
            "Weights: [-0.04110552  0.8138435  -0.17943771]\n",
            "--------------------------------\n",
            "Epoch: 138 / 500\n",
            "Train_loss: 13.1806940913303\n",
            "Test_loss: 9.24105448306909\n",
            "Weights: [-0.0411041   0.81386617 -0.17946098]\n",
            "--------------------------------\n",
            "Epoch: 139 / 500\n",
            "Train_loss: 13.180693225259802\n",
            "Test_loss: 9.240987283909197\n",
            "Weights: [-0.04110276  0.81388772 -0.17948309]\n",
            "--------------------------------\n",
            "Epoch: 140 / 500\n",
            "Train_loss: 13.180692442922792\n",
            "Test_loss: 9.240923422634541\n",
            "Weights: [-0.04110148  0.8139082  -0.1795041 ]\n",
            "--------------------------------\n",
            "Epoch: 141 / 500\n",
            "Train_loss: 13.180691736223752\n",
            "Test_loss: 9.240862733127898\n",
            "Weights: [-0.04110027  0.81392766 -0.17952408]\n",
            "--------------------------------\n",
            "Epoch: 142 / 500\n",
            "Train_loss: 13.180691097849843\n",
            "Test_loss: 9.240805057569924\n",
            "Weights: [-0.04109911  0.81394616 -0.17954306]\n",
            "--------------------------------\n",
            "Epoch: 143 / 500\n",
            "Train_loss: 13.180690521195249\n",
            "Test_loss: 9.240750246021726\n",
            "Weights: [-0.04109802  0.81396374 -0.17956111]\n",
            "--------------------------------\n",
            "Epoch: 144 / 500\n",
            "Train_loss: 13.180690000292817\n",
            "Test_loss: 9.240698156028667\n",
            "Weights: [-0.04109697  0.81398045 -0.17957826]\n",
            "--------------------------------\n",
            "Epoch: 145 / 500\n",
            "Train_loss: 13.180689529752312\n",
            "Test_loss: 9.240648652244445\n",
            "Weights: [-0.04109598  0.81399633 -0.17959455]\n",
            "--------------------------------\n",
            "Epoch: 146 / 500\n",
            "Train_loss: 13.180689104704642\n",
            "Test_loss: 9.240601606074149\n",
            "Weights: [-0.04109504  0.81401143 -0.17961004]\n",
            "--------------------------------\n",
            "Epoch: 147 / 500\n",
            "Train_loss: 13.18068872075146\n",
            "Test_loss: 9.240556895335553\n",
            "Weights: [-0.04109414  0.81402577 -0.17962477]\n",
            "--------------------------------\n",
            "Epoch: 148 / 500\n",
            "Train_loss: 13.180688373919672\n",
            "Test_loss: 9.240514403937565\n",
            "Weights: [-0.04109329  0.81403941 -0.17963876]\n",
            "--------------------------------\n",
            "Epoch: 149 / 500\n",
            "Train_loss: 13.180688060620302\n",
            "Test_loss: 9.240474021574927\n",
            "Weights: [-0.04109248  0.81405237 -0.17965206]\n",
            "--------------------------------\n",
            "Epoch: 150 / 500\n",
            "Train_loss: 13.180687777611361\n",
            "Test_loss: 9.24043564343844\n",
            "Weights: [-0.04109171  0.81406469 -0.1796647 ]\n",
            "--------------------------------\n",
            "Epoch: 151 / 500\n",
            "Train_loss: 13.180687521964316\n",
            "Test_loss: 9.24039916993978\n",
            "Weights: [-0.04109098  0.81407639 -0.17967672]\n",
            "--------------------------------\n",
            "Epoch: 152 / 500\n",
            "Train_loss: 13.180687291033758\n",
            "Test_loss: 9.240364506450248\n",
            "Weights: [-0.04109029  0.81408752 -0.17968813]\n",
            "--------------------------------\n",
            "Epoch: 153 / 500\n",
            "Train_loss: 13.180687082430042\n",
            "Test_loss: 9.240331563052706\n",
            "Weights: [-0.04108963  0.81409809 -0.17969899]\n",
            "--------------------------------\n",
            "Epoch: 154 / 500\n",
            "Train_loss: 13.18068689399457\n",
            "Test_loss: 9.240300254306018\n",
            "Weights: [-0.041089    0.81410814 -0.1797093 ]\n",
            "--------------------------------\n",
            "Epoch: 155 / 500\n",
            "Train_loss: 13.180686723777427\n",
            "Test_loss: 9.240270499021367\n",
            "Weights: [-0.0410884   0.81411769 -0.1797191 ]\n",
            "--------------------------------\n",
            "Epoch: 156 / 500\n",
            "Train_loss: 13.180686570017233\n",
            "Test_loss: 9.240242220049817\n",
            "Weights: [-0.04108784  0.81412677 -0.17972842]\n",
            "--------------------------------\n",
            "Epoch: 157 / 500\n",
            "Train_loss: 13.180686431122892\n",
            "Test_loss: 9.240215344080589\n",
            "Weights: [-0.0410873   0.8141354  -0.17973728]\n",
            "--------------------------------\n",
            "Epoch: 158 / 500\n",
            "Train_loss: 13.180686305657147\n",
            "Test_loss: 9.240189801449443\n",
            "Weights: [-0.04108678  0.8141436  -0.17974569]\n",
            "--------------------------------\n",
            "Epoch: 159 / 500\n",
            "Train_loss: 13.180686192321685\n",
            "Test_loss: 9.240165525956748\n",
            "Weights: [-0.0410863   0.8141514  -0.17975369]\n",
            "--------------------------------\n",
            "Epoch: 160 / 500\n",
            "Train_loss: 13.180686089943736\n",
            "Test_loss: 9.240142454694611\n",
            "Weights: [-0.04108583  0.81415881 -0.17976129]\n",
            "--------------------------------\n",
            "Epoch: 161 / 500\n",
            "Train_loss: 13.180685997463897\n",
            "Test_loss: 9.240120527882747\n",
            "Weights: [-0.04108539  0.81416585 -0.17976852]\n",
            "--------------------------------\n",
            "Epoch: 162 / 500\n",
            "Train_loss: 13.1806859139252\n",
            "Test_loss: 9.240099688712537\n",
            "Weights: [-0.04108498  0.81417254 -0.17977539]\n",
            "--------------------------------\n",
            "Epoch: 163 / 500\n",
            "Train_loss: 13.180685838463202\n",
            "Test_loss: 9.240079883198904\n",
            "Weights: [-0.04108458  0.8141789  -0.17978191]\n",
            "--------------------------------\n",
            "Epoch: 164 / 500\n",
            "Train_loss: 13.180685770297021\n",
            "Test_loss: 9.240061060039658\n",
            "Weights: [-0.0410842   0.81418494 -0.17978812]\n",
            "--------------------------------\n",
            "Epoch: 165 / 500\n",
            "Train_loss: 13.180685708721295\n",
            "Test_loss: 9.240043170481814\n",
            "Weights: [-0.04108384  0.81419069 -0.17979401]\n",
            "--------------------------------\n",
            "Epoch: 166 / 500\n",
            "Train_loss: 13.180685653098829\n",
            "Test_loss: 9.24002616819465\n",
            "Weights: [-0.0410835   0.81419615 -0.17979962]\n",
            "--------------------------------\n",
            "Epoch: 167 / 500\n",
            "Train_loss: 13.180685602854068\n",
            "Test_loss: 9.240010009149083\n",
            "Weights: [-0.04108318  0.81420134 -0.17980494]\n",
            "--------------------------------\n",
            "Epoch: 168 / 500\n",
            "Train_loss: 13.180685557467067\n",
            "Test_loss: 9.239994651503112\n",
            "Weights: [-0.04108287  0.81420627 -0.17981001]\n",
            "--------------------------------\n",
            "Epoch: 169 / 500\n",
            "Train_loss: 13.18068551646818\n",
            "Test_loss: 9.23998005549295\n",
            "Weights: [-0.04108258  0.81421096 -0.17981482]\n",
            "--------------------------------\n",
            "Epoch: 170 / 500\n",
            "Train_loss: 13.18068547943315\n",
            "Test_loss: 9.239966183329615\n",
            "Weights: [-0.0410823   0.81421541 -0.17981939]\n",
            "--------------------------------\n",
            "Epoch: 171 / 500\n",
            "Train_loss: 13.18068544597874\n",
            "Test_loss: 9.239952999100678\n",
            "Weights: [-0.04108203  0.81421965 -0.17982373]\n",
            "--------------------------------\n",
            "Epoch: 172 / 500\n",
            "Train_loss: 13.180685415758774\n",
            "Test_loss: 9.239940468676924\n",
            "Weights: [-0.04108178  0.81422367 -0.17982787]\n",
            "--------------------------------\n",
            "Epoch: 173 / 500\n",
            "Train_loss: 13.180685388460537\n",
            "Test_loss: 9.239928559623664\n",
            "Weights: [-0.04108154  0.8142275  -0.17983179]\n",
            "--------------------------------\n",
            "Epoch: 174 / 500\n",
            "Train_loss: 13.18068536380155\n",
            "Test_loss: 9.239917241116459\n",
            "Weights: [-0.04108131  0.81423114 -0.17983552]\n",
            "--------------------------------\n",
            "Epoch: 175 / 500\n",
            "Train_loss: 13.180685341526647\n",
            "Test_loss: 9.239906483861088\n",
            "Weights: [-0.0410811   0.81423459 -0.17983907]\n",
            "--------------------------------\n",
            "Epoch: 176 / 500\n",
            "Train_loss: 13.180685321405324\n",
            "Test_loss: 9.239896260017455\n",
            "Weights: [-0.04108089  0.81423788 -0.17984244]\n",
            "--------------------------------\n",
            "Epoch: 177 / 500\n",
            "Train_loss: 13.180685303229376\n",
            "Test_loss: 9.23988654312733\n",
            "Weights: [-0.0410807   0.814241   -0.17984564]\n",
            "--------------------------------\n",
            "Epoch: 178 / 500\n",
            "Train_loss: 13.180685286810716\n",
            "Test_loss: 9.239877308045656\n",
            "Weights: [-0.04108051  0.81424396 -0.17984869]\n",
            "--------------------------------\n",
            "Epoch: 179 / 500\n",
            "Train_loss: 13.180685271979444\n",
            "Test_loss: 9.239868530875317\n",
            "Weights: [-0.04108034  0.81424678 -0.17985158]\n",
            "--------------------------------\n",
            "Epoch: 180 / 500\n",
            "Train_loss: 13.18068525858209\n",
            "Test_loss: 9.239860188905112\n",
            "Weights: [-0.04108017  0.81424946 -0.17985433]\n",
            "--------------------------------\n",
            "Epoch: 181 / 500\n",
            "Train_loss: 13.18068524648002\n",
            "Test_loss: 9.239852260550858\n",
            "Weights: [-0.04108001  0.81425201 -0.17985694]\n",
            "--------------------------------\n",
            "Epoch: 182 / 500\n",
            "Train_loss: 13.180685235548003\n",
            "Test_loss: 9.239844725299392\n",
            "Weights: [-0.04107986  0.81425443 -0.17985943]\n",
            "--------------------------------\n",
            "Epoch: 183 / 500\n",
            "Train_loss: 13.180685225672919\n",
            "Test_loss: 9.239837563655383\n",
            "Weights: [-0.04107971  0.81425673 -0.17986179]\n",
            "--------------------------------\n",
            "Epoch: 184 / 500\n",
            "Train_loss: 13.180685216752577\n",
            "Test_loss: 9.239830757090784\n",
            "Weights: [-0.04107958  0.81425892 -0.17986403]\n",
            "--------------------------------\n",
            "Epoch: 185 / 500\n",
            "Train_loss: 13.180685208694673\n",
            "Test_loss: 9.239824287996779\n",
            "Weights: [-0.04107945  0.814261   -0.17986617]\n",
            "--------------------------------\n",
            "Epoch: 186 / 500\n",
            "Train_loss: 13.180685201415823\n",
            "Test_loss: 9.23981813963817\n",
            "Weights: [-0.04107932  0.81426297 -0.17986819]\n",
            "--------------------------------\n",
            "Epoch: 187 / 500\n",
            "Train_loss: 13.180685194840708\n",
            "Test_loss: 9.239812296109962\n",
            "Weights: [-0.04107921  0.81426485 -0.17987012]\n",
            "--------------------------------\n",
            "Epoch: 188 / 500\n",
            "Train_loss: 13.180685188901288\n",
            "Test_loss: 9.239806742296189\n",
            "Weights: [-0.0410791   0.81426663 -0.17987195]\n",
            "--------------------------------\n",
            "Epoch: 189 / 500\n",
            "Train_loss: 13.180685183536104\n",
            "Test_loss: 9.239801463830707\n",
            "Weights: [-0.04107899  0.81426833 -0.17987369]\n",
            "--------------------------------\n",
            "Epoch: 190 / 500\n",
            "Train_loss: 13.180685178689638\n",
            "Test_loss: 9.23979644705999\n",
            "Weights: [-0.04107889  0.81426994 -0.17987535]\n",
            "--------------------------------\n",
            "Epoch: 191 / 500\n",
            "Train_loss: 13.180685174311733\n",
            "Test_loss: 9.239791679007764\n",
            "Weights: [-0.04107879  0.81427147 -0.17987692]\n",
            "--------------------------------\n",
            "Epoch: 192 / 500\n",
            "Train_loss: 13.180685170357098\n",
            "Test_loss: 9.239787147341383\n",
            "Weights: [-0.0410787   0.81427293 -0.17987841]\n",
            "--------------------------------\n",
            "Epoch: 193 / 500\n",
            "Train_loss: 13.180685166784805\n",
            "Test_loss: 9.239782840339878\n",
            "Weights: [-0.04107862  0.81427431 -0.17987983]\n",
            "--------------------------------\n",
            "Epoch: 194 / 500\n",
            "Train_loss: 13.180685163557891\n",
            "Test_loss: 9.23977874686363\n",
            "Weights: [-0.04107853  0.81427563 -0.17988118]\n",
            "--------------------------------\n",
            "Epoch: 195 / 500\n",
            "Train_loss: 13.180685160642959\n",
            "Test_loss: 9.239774856325491\n",
            "Weights: [-0.04107846  0.81427688 -0.17988247]\n",
            "--------------------------------\n",
            "Epoch: 196 / 500\n",
            "Train_loss: 13.180685158009844\n",
            "Test_loss: 9.239771158663379\n",
            "Weights: [-0.04107838  0.81427807 -0.17988369]\n",
            "--------------------------------\n",
            "Epoch: 197 / 500\n",
            "Train_loss: 13.180685155631313\n",
            "Test_loss: 9.239767644314242\n",
            "Weights: [-0.04107831  0.8142792  -0.17988484]\n",
            "--------------------------------\n",
            "Epoch: 198 / 500\n",
            "Train_loss: 13.180685153482735\n",
            "Test_loss: 9.239764304189269\n",
            "Weights: [-0.04107824  0.81428027 -0.17988595]\n",
            "--------------------------------\n",
            "Epoch: 199 / 500\n",
            "Train_loss: 13.18068515154189\n",
            "Test_loss: 9.239761129650379\n",
            "Weights: [-0.04107818  0.81428129 -0.17988699]\n",
            "--------------------------------\n",
            "Epoch: 200 / 500\n",
            "Train_loss: 13.18068514978869\n",
            "Test_loss: 9.239758112487866\n",
            "Weights: [-0.04107812  0.81428226 -0.17988799]\n",
            "--------------------------------\n",
            "Epoch: 201 / 500\n",
            "Train_loss: 13.180685148204995\n",
            "Test_loss: 9.239755244899126\n",
            "Weights: [-0.04107806  0.81428318 -0.17988893]\n",
            "--------------------------------\n",
            "Epoch: 202 / 500\n",
            "Train_loss: 13.180685146774412\n",
            "Test_loss: 9.239752519468475\n",
            "Weights: [-0.04107801  0.81428405 -0.17988983]\n",
            "--------------------------------\n",
            "Epoch: 203 / 500\n",
            "Train_loss: 13.18068514548214\n",
            "Test_loss: 9.239749929147957\n",
            "Weights: [-0.04107795  0.81428489 -0.17989069]\n",
            "--------------------------------\n",
            "Epoch: 204 / 500\n",
            "Train_loss: 13.18068514431481\n",
            "Test_loss: 9.239747467239098\n",
            "Weights: [-0.0410779   0.81428568 -0.1798915 ]\n",
            "--------------------------------\n",
            "Epoch: 205 / 500\n",
            "Train_loss: 13.18068514326034\n",
            "Test_loss: 9.239745127375572\n",
            "Weights: [-0.04107786  0.81428643 -0.17989227]\n",
            "--------------------------------\n",
            "Epoch: 206 / 500\n",
            "Train_loss: 13.180685142307814\n",
            "Test_loss: 9.239742903506729\n",
            "Weights: [-0.04107781  0.81428714 -0.179893  ]\n",
            "--------------------------------\n",
            "Epoch: 207 / 500\n",
            "Train_loss: 13.180685141447386\n",
            "Test_loss: 9.23974078988193\n",
            "Weights: [-0.04107777  0.81428782 -0.1798937 ]\n",
            "--------------------------------\n",
            "Epoch: 208 / 500\n",
            "Train_loss: 13.180685140670143\n",
            "Test_loss: 9.239738781035674\n",
            "Weights: [-0.04107773  0.81428847 -0.17989436]\n",
            "--------------------------------\n",
            "Epoch: 209 / 500\n",
            "Train_loss: 13.180685139968048\n",
            "Test_loss: 9.23973687177346\n",
            "Weights: [-0.04107769  0.81428908 -0.17989499]\n",
            "--------------------------------\n",
            "Epoch: 210 / 500\n",
            "Train_loss: 13.180685139333827\n",
            "Test_loss: 9.239735057158331\n",
            "Weights: [-0.04107766  0.81428967 -0.17989559]\n",
            "--------------------------------\n",
            "Epoch: 211 / 500\n",
            "Train_loss: 13.180685138760929\n",
            "Test_loss: 9.239733332498128\n",
            "Weights: [-0.04107762  0.81429022 -0.17989616]\n",
            "--------------------------------\n",
            "Epoch: 212 / 500\n",
            "Train_loss: 13.180685138243419\n",
            "Test_loss: 9.239731693333319\n",
            "Weights: [-0.04107759  0.81429075 -0.1798967 ]\n",
            "--------------------------------\n",
            "Epoch: 213 / 500\n",
            "Train_loss: 13.180685137775942\n",
            "Test_loss: 9.239730135425477\n",
            "Weights: [-0.04107756  0.81429125 -0.17989721]\n",
            "--------------------------------\n",
            "Epoch: 214 / 500\n",
            "Train_loss: 13.180685137353661\n",
            "Test_loss: 9.239728654746328\n",
            "Weights: [-0.04107753  0.81429172 -0.1798977 ]\n",
            "--------------------------------\n",
            "Epoch: 215 / 500\n",
            "Train_loss: 13.18068513697221\n",
            "Test_loss: 9.2397272474673\n",
            "Weights: [-0.0410775   0.81429218 -0.17989816]\n",
            "--------------------------------\n",
            "Epoch: 216 / 500\n",
            "Train_loss: 13.180685136627638\n",
            "Test_loss: 9.239725909949655\n",
            "Weights: [-0.04107747  0.8142926  -0.17989861]\n",
            "--------------------------------\n",
            "Epoch: 217 / 500\n",
            "Train_loss: 13.180685136316377\n",
            "Test_loss: 9.239724638735044\n",
            "Weights: [-0.04107745  0.81429301 -0.17989903]\n",
            "--------------------------------\n",
            "Epoch: 218 / 500\n",
            "Train_loss: 13.18068513603521\n",
            "Test_loss: 9.239723430536582\n",
            "Weights: [-0.04107742  0.8142934  -0.17989942]\n",
            "--------------------------------\n",
            "Epoch: 219 / 500\n",
            "Train_loss: 13.180685135781232\n",
            "Test_loss: 9.23972228223034\n",
            "Weights: [-0.0410774   0.81429377 -0.1798998 ]\n",
            "--------------------------------\n",
            "Epoch: 220 / 500\n",
            "Train_loss: 13.1806851355518\n",
            "Test_loss: 9.23972119084726\n",
            "Weights: [-0.04107738  0.81429412 -0.17990016]\n",
            "--------------------------------\n",
            "Epoch: 221 / 500\n",
            "Train_loss: 13.180685135344557\n",
            "Test_loss: 9.23972015356549\n",
            "Weights: [-0.04107736  0.81429445 -0.1799005 ]\n",
            "--------------------------------\n",
            "Epoch: 222 / 500\n",
            "Train_loss: 13.180685135157349\n",
            "Test_loss: 9.239719167703058\n",
            "Weights: [-0.04107734  0.81429477 -0.17990083]\n",
            "--------------------------------\n",
            "Epoch: 223 / 500\n",
            "Train_loss: 13.180685134988238\n",
            "Test_loss: 9.239718230710974\n",
            "Weights: [-0.04107732  0.81429507 -0.17990114]\n",
            "--------------------------------\n",
            "Epoch: 224 / 500\n",
            "Train_loss: 13.180685134835484\n",
            "Test_loss: 9.239717340166605\n",
            "Weights: [-0.0410773   0.81429536 -0.17990143]\n",
            "--------------------------------\n",
            "Epoch: 225 / 500\n",
            "Train_loss: 13.180685134697491\n",
            "Test_loss: 9.239716493767418\n",
            "Weights: [-0.04107728  0.81429563 -0.17990171]\n",
            "--------------------------------\n",
            "Epoch: 226 / 500\n",
            "Train_loss: 13.180685134572842\n",
            "Test_loss: 9.23971568932504\n",
            "Weights: [-0.04107727  0.81429589 -0.17990198]\n",
            "--------------------------------\n",
            "Epoch: 227 / 500\n",
            "Train_loss: 13.180685134460244\n",
            "Test_loss: 9.23971492475957\n",
            "Weights: [-0.04107725  0.81429613 -0.17990223]\n",
            "--------------------------------\n",
            "Epoch: 228 / 500\n",
            "Train_loss: 13.180685134358535\n",
            "Test_loss: 9.239714198094239\n",
            "Weights: [-0.04107724  0.81429637 -0.17990247]\n",
            "--------------------------------\n",
            "Epoch: 229 / 500\n",
            "Train_loss: 13.180685134266655\n",
            "Test_loss: 9.239713507450256\n",
            "Weights: [-0.04107722  0.81429659 -0.1799027 ]\n",
            "--------------------------------\n",
            "Epoch: 230 / 500\n",
            "Train_loss: 13.180685134183658\n",
            "Test_loss: 9.239712851041977\n",
            "Weights: [-0.04107721  0.8142968  -0.17990291]\n",
            "--------------------------------\n",
            "Epoch: 231 / 500\n",
            "Train_loss: 13.180685134108687\n",
            "Test_loss: 9.239712227172276\n",
            "Weights: [-0.0410772   0.814297   -0.17990312]\n",
            "--------------------------------\n",
            "Epoch: 232 / 500\n",
            "Train_loss: 13.18068513404097\n",
            "Test_loss: 9.239711634228172\n",
            "Weights: [-0.04107719  0.81429719 -0.17990331]\n",
            "--------------------------------\n",
            "Epoch: 233 / 500\n",
            "Train_loss: 13.18068513397979\n",
            "Test_loss: 9.239711070676629\n",
            "Weights: [-0.04107717  0.81429737 -0.1799035 ]\n",
            "--------------------------------\n",
            "Epoch: 234 / 500\n",
            "Train_loss: 13.180685133924532\n",
            "Test_loss: 9.239710535060619\n",
            "Weights: [-0.04107716  0.81429755 -0.17990368]\n",
            "--------------------------------\n",
            "Epoch: 235 / 500\n",
            "Train_loss: 13.180685133874617\n",
            "Test_loss: 9.239710025995334\n",
            "Weights: [-0.04107715  0.81429771 -0.17990384]\n",
            "--------------------------------\n",
            "Epoch: 236 / 500\n",
            "Train_loss: 13.180685133829524\n",
            "Test_loss: 9.23970954216463\n",
            "Weights: [-0.04107714  0.81429786 -0.179904  ]\n",
            "--------------------------------\n",
            "Epoch: 237 / 500\n",
            "Train_loss: 13.180685133788794\n",
            "Test_loss: 9.239709082317596\n",
            "Weights: [-0.04107713  0.81429801 -0.17990416]\n",
            "--------------------------------\n",
            "Epoch: 238 / 500\n",
            "Train_loss: 13.180685133751995\n",
            "Test_loss: 9.239708645265331\n",
            "Weights: [-0.04107712  0.81429815 -0.1799043 ]\n",
            "--------------------------------\n",
            "Epoch: 239 / 500\n",
            "Train_loss: 13.18068513371876\n",
            "Test_loss: 9.23970822987788\n",
            "Weights: [-0.04107712  0.81429829 -0.17990444]\n",
            "--------------------------------\n",
            "Epoch: 240 / 500\n",
            "Train_loss: 13.180685133688739\n",
            "Test_loss: 9.2397078350813\n",
            "Weights: [-0.04107711  0.81429841 -0.17990457]\n",
            "--------------------------------\n",
            "Epoch: 241 / 500\n",
            "Train_loss: 13.180685133661617\n",
            "Test_loss: 9.239707459854873\n",
            "Weights: [-0.0410771   0.81429853 -0.17990469]\n",
            "--------------------------------\n",
            "Epoch: 242 / 500\n",
            "Train_loss: 13.180685133637118\n",
            "Test_loss: 9.239707103228499\n",
            "Weights: [-0.04107709  0.81429865 -0.17990481]\n",
            "--------------------------------\n",
            "Epoch: 243 / 500\n",
            "Train_loss: 13.18068513361499\n",
            "Test_loss: 9.239706764280156\n",
            "Weights: [-0.04107709  0.81429876 -0.17990492]\n",
            "--------------------------------\n",
            "Epoch: 244 / 500\n",
            "Train_loss: 13.180685133595\n",
            "Test_loss: 9.239706442133535\n",
            "Weights: [-0.04107708  0.81429886 -0.17990503]\n",
            "--------------------------------\n",
            "Epoch: 245 / 500\n",
            "Train_loss: 13.180685133576944\n",
            "Test_loss: 9.239706135955759\n",
            "Weights: [-0.04107707  0.81429896 -0.17990513]\n",
            "--------------------------------\n",
            "Epoch: 246 / 500\n",
            "Train_loss: 13.18068513356063\n",
            "Test_loss: 9.239705844955244\n",
            "Weights: [-0.04107707  0.81429905 -0.17990522]\n",
            "--------------------------------\n",
            "Epoch: 247 / 500\n",
            "Train_loss: 13.180685133545895\n",
            "Test_loss: 9.239705568379643\n",
            "Weights: [-0.04107706  0.81429914 -0.17990531]\n",
            "--------------------------------\n",
            "Epoch: 248 / 500\n",
            "Train_loss: 13.180685133532583\n",
            "Test_loss: 9.239705305513912\n",
            "Weights: [-0.04107706  0.81429923 -0.1799054 ]\n",
            "--------------------------------\n",
            "Epoch: 249 / 500\n",
            "Train_loss: 13.18068513352056\n",
            "Test_loss: 9.23970505567844\n",
            "Weights: [-0.04107705  0.81429931 -0.17990548]\n",
            "--------------------------------\n",
            "Epoch: 250 / 500\n",
            "Train_loss: 13.180685133509703\n",
            "Test_loss: 9.239704818227313\n",
            "Weights: [-0.04107705  0.81429938 -0.17990556]\n",
            "--------------------------------\n",
            "Epoch: 251 / 500\n",
            "Train_loss: 13.18068513349989\n",
            "Test_loss: 9.239704592546637\n",
            "Weights: [-0.04107704  0.81429945 -0.17990564]\n",
            "--------------------------------\n",
            "Epoch: 252 / 500\n",
            "Train_loss: 13.180685133491028\n",
            "Test_loss: 9.239704378052949\n",
            "Weights: [-0.04107704  0.81429952 -0.17990571]\n",
            "--------------------------------\n",
            "Epoch: 253 / 500\n",
            "Train_loss: 13.180685133483024\n",
            "Test_loss: 9.239704174191697\n",
            "Weights: [-0.04107704  0.81429959 -0.17990577]\n",
            "--------------------------------\n",
            "Epoch: 254 / 500\n",
            "Train_loss: 13.18068513347579\n",
            "Test_loss: 9.239703980435834\n",
            "Weights: [-0.04107703  0.81429965 -0.17990584]\n",
            "--------------------------------\n",
            "Epoch: 255 / 500\n",
            "Train_loss: 13.18068513346926\n",
            "Test_loss: 9.239703796284438\n",
            "Weights: [-0.04107703  0.81429971 -0.1799059 ]\n",
            "--------------------------------\n",
            "Epoch: 256 / 500\n",
            "Train_loss: 13.180685133463356\n",
            "Test_loss: 9.239703621261405\n",
            "Weights: [-0.04107702  0.81429977 -0.17990596]\n",
            "--------------------------------\n",
            "Epoch: 257 / 500\n",
            "Train_loss: 13.180685133458027\n",
            "Test_loss: 9.239703454914245\n",
            "Weights: [-0.04107702  0.81429982 -0.17990601]\n",
            "--------------------------------\n",
            "Epoch: 258 / 500\n",
            "Train_loss: 13.180685133453212\n",
            "Test_loss: 9.239703296812891\n",
            "Weights: [-0.04107702  0.81429987 -0.17990606]\n",
            "--------------------------------\n",
            "Epoch: 259 / 500\n",
            "Train_loss: 13.180685133448865\n",
            "Test_loss: 9.239703146548607\n",
            "Weights: [-0.04107701  0.81429992 -0.17990611]\n",
            "--------------------------------\n",
            "Epoch: 260 / 500\n",
            "Train_loss: 13.180685133444936\n",
            "Test_loss: 9.239703003732894\n",
            "Weights: [-0.04107701  0.81429997 -0.17990616]\n",
            "--------------------------------\n",
            "Epoch: 261 / 500\n",
            "Train_loss: 13.180685133441385\n",
            "Test_loss: 9.239702867996533\n",
            "Weights: [-0.04107701  0.81430001 -0.1799062 ]\n",
            "--------------------------------\n",
            "Epoch: 262 / 500\n",
            "Train_loss: 13.18068513343818\n",
            "Test_loss: 9.239702738988601\n",
            "Weights: [-0.04107701  0.81430005 -0.17990625]\n",
            "--------------------------------\n",
            "Epoch: 263 / 500\n",
            "Train_loss: 13.180685133435286\n",
            "Test_loss: 9.239702616375565\n",
            "Weights: [-0.041077    0.81430009 -0.17990629]\n",
            "--------------------------------\n",
            "Epoch: 264 / 500\n",
            "Train_loss: 13.180685133432668\n",
            "Test_loss: 9.239702499840439\n",
            "Weights: [-0.041077    0.81430013 -0.17990633]\n",
            "--------------------------------\n",
            "Epoch: 265 / 500\n",
            "Train_loss: 13.180685133430304\n",
            "Test_loss: 9.23970238908193\n",
            "Weights: [-0.041077    0.81430016 -0.17990636]\n",
            "--------------------------------\n",
            "Epoch: 266 / 500\n",
            "Train_loss: 13.18068513342817\n",
            "Test_loss: 9.239702283813704\n",
            "Weights: [-0.041077   0.8143002 -0.1799064]\n",
            "--------------------------------\n",
            "Epoch: 267 / 500\n",
            "Train_loss: 13.180685133426241\n",
            "Test_loss: 9.239702183763596\n",
            "Weights: [-0.041077    0.81430023 -0.17990643]\n",
            "--------------------------------\n",
            "Epoch: 268 / 500\n",
            "Train_loss: 13.1806851334245\n",
            "Test_loss: 9.23970208867295\n",
            "Weights: [-0.04107699  0.81430026 -0.17990646]\n",
            "--------------------------------\n",
            "Epoch: 269 / 500\n",
            "Train_loss: 13.180685133422925\n",
            "Test_loss: 9.239701998295926\n",
            "Weights: [-0.04107699  0.81430029 -0.17990649]\n",
            "--------------------------------\n",
            "Epoch: 270 / 500\n",
            "Train_loss: 13.180685133421507\n",
            "Test_loss: 9.239701912398868\n",
            "Weights: [-0.04107699  0.81430032 -0.17990652]\n",
            "--------------------------------\n",
            "Epoch: 271 / 500\n",
            "Train_loss: 13.180685133420221\n",
            "Test_loss: 9.2397018307597\n",
            "Weights: [-0.04107699  0.81430034 -0.17990655]\n",
            "--------------------------------\n",
            "Epoch: 272 / 500\n",
            "Train_loss: 13.18068513341906\n",
            "Test_loss: 9.239701753167372\n",
            "Weights: [-0.04107699  0.81430037 -0.17990657]\n",
            "--------------------------------\n",
            "Epoch: 273 / 500\n",
            "Train_loss: 13.180685133418013\n",
            "Test_loss: 9.23970167942127\n",
            "Weights: [-0.04107698  0.81430039 -0.1799066 ]\n",
            "--------------------------------\n",
            "Epoch: 274 / 500\n",
            "Train_loss: 13.18068513341707\n",
            "Test_loss: 9.239701609330748\n",
            "Weights: [-0.04107698  0.81430041 -0.17990662]\n",
            "--------------------------------\n",
            "Epoch: 275 / 500\n",
            "Train_loss: 13.180685133416214\n",
            "Test_loss: 9.239701542714588\n",
            "Weights: [-0.04107698  0.81430043 -0.17990664]\n",
            "--------------------------------\n",
            "Epoch: 276 / 500\n",
            "Train_loss: 13.180685133415441\n",
            "Test_loss: 9.239701479400575\n",
            "Weights: [-0.04107698  0.81430046 -0.17990666]\n",
            "--------------------------------\n",
            "Epoch: 277 / 500\n",
            "Train_loss: 13.180685133414741\n",
            "Test_loss: 9.239701419225018\n",
            "Weights: [-0.04107698  0.81430047 -0.17990668]\n",
            "--------------------------------\n",
            "Epoch: 278 / 500\n",
            "Train_loss: 13.180685133414112\n",
            "Test_loss: 9.239701362032346\n",
            "Weights: [-0.04107698  0.81430049 -0.1799067 ]\n",
            "--------------------------------\n",
            "Epoch: 279 / 500\n",
            "Train_loss: 13.180685133413544\n",
            "Test_loss: 9.239701307674697\n",
            "Weights: [-0.04107698  0.81430051 -0.17990672]\n",
            "--------------------------------\n",
            "Epoch: 280 / 500\n",
            "Train_loss: 13.180685133413029\n",
            "Test_loss: 9.239701256011543\n",
            "Weights: [-0.04107698  0.81430053 -0.17990674]\n",
            "--------------------------------\n",
            "Epoch: 281 / 500\n",
            "Train_loss: 13.180685133412567\n",
            "Test_loss: 9.239701206909313\n",
            "Weights: [-0.04107698  0.81430054 -0.17990675]\n",
            "--------------------------------\n",
            "Epoch: 282 / 500\n",
            "Train_loss: 13.180685133412148\n",
            "Test_loss: 9.239701160241065\n",
            "Weights: [-0.04107697  0.81430056 -0.17990677]\n",
            "--------------------------------\n",
            "Epoch: 283 / 500\n",
            "Train_loss: 13.18068513341177\n",
            "Test_loss: 9.23970111588615\n",
            "Weights: [-0.04107697  0.81430057 -0.17990678]\n",
            "--------------------------------\n",
            "Epoch: 284 / 500\n",
            "Train_loss: 13.180685133411426\n",
            "Test_loss: 9.239701073729893\n",
            "Weights: [-0.04107697  0.81430059 -0.1799068 ]\n",
            "--------------------------------\n",
            "Epoch: 285 / 500\n",
            "Train_loss: 13.180685133411115\n",
            "Test_loss: 9.239701033663309\n",
            "Weights: [-0.04107697  0.8143006  -0.17990681]\n",
            "--------------------------------\n",
            "Epoch: 286 / 500\n",
            "Train_loss: 13.180685133410835\n",
            "Test_loss: 9.239700995582812\n",
            "Weights: [-0.04107697  0.81430061 -0.17990682]\n",
            "--------------------------------\n",
            "Epoch: 287 / 500\n",
            "Train_loss: 13.180685133410583\n",
            "Test_loss: 9.239700959389948\n",
            "Weights: [-0.04107697  0.81430062 -0.17990683]\n",
            "--------------------------------\n",
            "Epoch: 288 / 500\n",
            "Train_loss: 13.180685133410357\n",
            "Test_loss: 9.239700924991155\n",
            "Weights: [-0.04107697  0.81430063 -0.17990685]\n",
            "--------------------------------\n",
            "Epoch: 289 / 500\n",
            "Train_loss: 13.180685133410151\n",
            "Test_loss: 9.239700892297503\n",
            "Weights: [-0.04107697  0.81430064 -0.17990686]\n",
            "--------------------------------\n",
            "Epoch: 290 / 500\n",
            "Train_loss: 13.180685133409963\n",
            "Test_loss: 9.23970086122446\n",
            "Weights: [-0.04107697  0.81430065 -0.17990687]\n",
            "--------------------------------\n",
            "Epoch: 291 / 500\n",
            "Train_loss: 13.180685133409794\n",
            "Test_loss: 9.239700831691692\n",
            "Weights: [-0.04107697  0.81430066 -0.17990688]\n",
            "--------------------------------\n",
            "Epoch: 292 / 500\n",
            "Train_loss: 13.180685133409646\n",
            "Test_loss: 9.239700803622865\n",
            "Weights: [-0.04107697  0.81430067 -0.17990689]\n",
            "--------------------------------\n",
            "Epoch: 293 / 500\n",
            "Train_loss: 13.18068513340951\n",
            "Test_loss: 9.239700776945392\n",
            "Weights: [-0.04107697  0.81430068 -0.17990689]\n",
            "--------------------------------\n",
            "Epoch: 294 / 500\n",
            "Train_loss: 13.180685133409384\n",
            "Test_loss: 9.239700751590316\n",
            "Weights: [-0.04107697  0.81430069 -0.1799069 ]\n",
            "--------------------------------\n",
            "Epoch: 295 / 500\n",
            "Train_loss: 13.18068513340927\n",
            "Test_loss: 9.239700727492085\n",
            "Weights: [-0.04107697  0.8143007  -0.17990691]\n",
            "--------------------------------\n",
            "Epoch: 296 / 500\n",
            "Train_loss: 13.180685133409174\n",
            "Test_loss: 9.239700704588389\n",
            "Weights: [-0.04107697  0.8143007  -0.17990692]\n",
            "--------------------------------\n",
            "Epoch: 297 / 500\n",
            "Train_loss: 13.180685133409082\n",
            "Test_loss: 9.239700682820024\n",
            "Weights: [-0.04107696  0.81430071 -0.17990693]\n",
            "--------------------------------\n",
            "Epoch: 298 / 500\n",
            "Train_loss: 13.180685133408996\n",
            "Test_loss: 9.239700662130707\n",
            "Weights: [-0.04107696  0.81430072 -0.17990693]\n",
            "--------------------------------\n",
            "Epoch: 299 / 500\n",
            "Train_loss: 13.180685133408923\n",
            "Test_loss: 9.239700642466953\n",
            "Weights: [-0.04107696  0.81430072 -0.17990694]\n",
            "--------------------------------\n",
            "Epoch: 300 / 500\n",
            "Train_loss: 13.180685133408854\n",
            "Test_loss: 9.239700623777924\n",
            "Weights: [-0.04107696  0.81430073 -0.17990694]\n",
            "--------------------------------\n",
            "Epoch: 301 / 500\n",
            "Train_loss: 13.180685133408794\n",
            "Test_loss: 9.239700606015305\n",
            "Weights: [-0.04107696  0.81430074 -0.17990695]\n",
            "--------------------------------\n",
            "Epoch: 302 / 500\n",
            "Train_loss: 13.18068513340874\n",
            "Test_loss: 9.23970058913317\n",
            "Weights: [-0.04107696  0.81430074 -0.17990696]\n",
            "--------------------------------\n",
            "Epoch: 303 / 500\n",
            "Train_loss: 13.180685133408689\n",
            "Test_loss: 9.239700573087879\n",
            "Weights: [-0.04107696  0.81430075 -0.17990696]\n",
            "--------------------------------\n",
            "Epoch: 304 / 500\n",
            "Train_loss: 13.180685133408646\n",
            "Test_loss: 9.239700557837944\n",
            "Weights: [-0.04107696  0.81430075 -0.17990697]\n",
            "--------------------------------\n",
            "Epoch: 305 / 500\n",
            "Train_loss: 13.180685133408604\n",
            "Test_loss: 9.239700543343949\n",
            "Weights: [-0.04107696  0.81430076 -0.17990697]\n",
            "--------------------------------\n",
            "Epoch: 306 / 500\n",
            "Train_loss: 13.18068513340857\n",
            "Test_loss: 9.239700529568408\n",
            "Weights: [-0.04107696  0.81430076 -0.17990698]\n",
            "--------------------------------\n",
            "Epoch: 307 / 500\n",
            "Train_loss: 13.180685133408536\n",
            "Test_loss: 9.23970051647572\n",
            "Weights: [-0.04107696  0.81430076 -0.17990698]\n",
            "--------------------------------\n",
            "Epoch: 308 / 500\n",
            "Train_loss: 13.180685133408502\n",
            "Test_loss: 9.239700504032031\n",
            "Weights: [-0.04107696  0.81430077 -0.17990698]\n",
            "--------------------------------\n",
            "Epoch: 309 / 500\n",
            "Train_loss: 13.180685133408476\n",
            "Test_loss: 9.23970049220517\n",
            "Weights: [-0.04107696  0.81430077 -0.17990699]\n",
            "--------------------------------\n",
            "Epoch: 310 / 500\n",
            "Train_loss: 13.180685133408454\n",
            "Test_loss: 9.239700480964563\n",
            "Weights: [-0.04107696  0.81430078 -0.17990699]\n",
            "--------------------------------\n",
            "Epoch: 311 / 500\n",
            "Train_loss: 13.180685133408433\n",
            "Test_loss: 9.239700470281154\n",
            "Weights: [-0.04107696  0.81430078 -0.179907  ]\n",
            "--------------------------------\n",
            "Epoch: 312 / 500\n",
            "Train_loss: 13.180685133408412\n",
            "Test_loss: 9.239700460127311\n",
            "Weights: [-0.04107696  0.81430078 -0.179907  ]\n",
            "--------------------------------\n",
            "Epoch: 313 / 500\n",
            "Train_loss: 13.180685133408392\n",
            "Test_loss: 9.239700450476793\n",
            "Weights: [-0.04107696  0.81430079 -0.179907  ]\n",
            "--------------------------------\n",
            "Epoch: 314 / 500\n",
            "Train_loss: 13.180685133408378\n",
            "Test_loss: 9.239700441304644\n",
            "Weights: [-0.04107696  0.81430079 -0.179907  ]\n",
            "--------------------------------\n",
            "Epoch: 315 / 500\n",
            "Train_loss: 13.180685133408366\n",
            "Test_loss: 9.239700432587158\n",
            "Weights: [-0.04107696  0.81430079 -0.17990701]\n",
            "--------------------------------\n",
            "Epoch: 316 / 500\n",
            "Train_loss: 13.18068513340835\n",
            "Test_loss: 9.239700424301796\n",
            "Weights: [-0.04107696  0.81430079 -0.17990701]\n",
            "--------------------------------\n",
            "Epoch: 317 / 500\n",
            "Train_loss: 13.180685133408337\n",
            "Test_loss: 9.239700416427132\n",
            "Weights: [-0.04107696  0.8143008  -0.17990701]\n",
            "--------------------------------\n",
            "Epoch: 318 / 500\n",
            "Train_loss: 13.180685133408327\n",
            "Test_loss: 9.239700408942815\n",
            "Weights: [-0.04107696  0.8143008  -0.17990702]\n",
            "--------------------------------\n",
            "Epoch: 319 / 500\n",
            "Train_loss: 13.18068513340832\n",
            "Test_loss: 9.239700401829493\n",
            "Weights: [-0.04107696  0.8143008  -0.17990702]\n",
            "--------------------------------\n",
            "Epoch: 320 / 500\n",
            "Train_loss: 13.18068513340831\n",
            "Test_loss: 9.239700395068773\n",
            "Weights: [-0.04107696  0.8143008  -0.17990702]\n",
            "--------------------------------\n",
            "Epoch: 321 / 500\n",
            "Train_loss: 13.1806851334083\n",
            "Test_loss: 9.239700388643179\n",
            "Weights: [-0.04107696  0.81430081 -0.17990702]\n",
            "--------------------------------\n",
            "Epoch: 322 / 500\n",
            "Train_loss: 13.180685133408293\n",
            "Test_loss: 9.239700382536105\n",
            "Weights: [-0.04107696  0.81430081 -0.17990702]\n",
            "--------------------------------\n",
            "Epoch: 323 / 500\n",
            "Train_loss: 13.180685133408286\n",
            "Test_loss: 9.23970037673175\n",
            "Weights: [-0.04107696  0.81430081 -0.17990703]\n",
            "--------------------------------\n",
            "Epoch: 324 / 500\n",
            "Train_loss: 13.180685133408282\n",
            "Test_loss: 9.23970037121512\n",
            "Weights: [-0.04107696  0.81430081 -0.17990703]\n",
            "--------------------------------\n",
            "Epoch: 325 / 500\n",
            "Train_loss: 13.180685133408275\n",
            "Test_loss: 9.239700365971945\n",
            "Weights: [-0.04107696  0.81430081 -0.17990703]\n",
            "--------------------------------\n",
            "Epoch: 326 / 500\n",
            "Train_loss: 13.180685133408268\n",
            "Test_loss: 9.239700360988675\n",
            "Weights: [-0.04107696  0.81430081 -0.17990703]\n",
            "--------------------------------\n",
            "Epoch: 327 / 500\n",
            "Train_loss: 13.180685133408268\n",
            "Test_loss: 9.239700356252415\n",
            "Weights: [-0.04107696  0.81430082 -0.17990703]\n",
            "--------------------------------\n",
            "Epoch: 328 / 500\n",
            "Train_loss: 13.180685133408264\n",
            "Test_loss: 9.239700351750939\n",
            "Weights: [-0.04107696  0.81430082 -0.17990703]\n",
            "--------------------------------\n",
            "Epoch: 329 / 500\n",
            "Train_loss: 13.180685133408257\n",
            "Test_loss: 9.239700347472594\n",
            "Weights: [-0.04107696  0.81430082 -0.17990704]\n",
            "--------------------------------\n",
            "Epoch: 330 / 500\n",
            "Train_loss: 13.180685133408256\n",
            "Test_loss: 9.239700343406327\n",
            "Weights: [-0.04107696  0.81430082 -0.17990704]\n",
            "--------------------------------\n",
            "Epoch: 331 / 500\n",
            "Train_loss: 13.180685133408254\n",
            "Test_loss: 9.23970033954162\n",
            "Weights: [-0.04107696  0.81430082 -0.17990704]\n",
            "--------------------------------\n",
            "Epoch: 332 / 500\n",
            "Train_loss: 13.180685133408254\n",
            "Test_loss: 9.23970033586849\n",
            "Weights: [-0.04107696  0.81430082 -0.17990704]\n",
            "--------------------------------\n",
            "Epoch: 333 / 500\n",
            "Train_loss: 13.180685133408248\n",
            "Test_loss: 9.239700332377433\n",
            "Weights: [-0.04107696  0.81430082 -0.17990704]\n",
            "--------------------------------\n",
            "Epoch: 334 / 500\n",
            "Train_loss: 13.180685133408245\n",
            "Test_loss: 9.239700329059426\n",
            "Weights: [-0.04107696  0.81430082 -0.17990704]\n",
            "--------------------------------\n",
            "Epoch: 335 / 500\n",
            "Train_loss: 13.180685133408245\n",
            "Test_loss: 9.239700325905895\n",
            "Weights: [-0.04107696  0.81430083 -0.17990704]\n",
            "--------------------------------\n",
            "Epoch: 336 / 500\n",
            "Train_loss: 13.180685133408245\n",
            "Test_loss: 9.239700322908678\n",
            "Weights: [-0.04107696  0.81430083 -0.17990704]\n",
            "--------------------------------\n",
            "Epoch: 337 / 500\n",
            "Train_loss: 13.180685133408243\n",
            "Test_loss: 9.239700320060034\n",
            "Weights: [-0.04107696  0.81430083 -0.17990704]\n",
            "--------------------------------\n",
            "Epoch: 338 / 500\n",
            "Train_loss: 13.180685133408243\n",
            "Test_loss: 9.239700317352598\n",
            "Weights: [-0.04107696  0.81430083 -0.17990705]\n",
            "--------------------------------\n",
            "Epoch: 339 / 500\n",
            "Train_loss: 13.180685133408238\n",
            "Test_loss: 9.23970031477937\n",
            "Weights: [-0.04107696  0.81430083 -0.17990705]\n",
            "--------------------------------\n",
            "Epoch: 340 / 500\n",
            "Train_loss: 13.18068513340824\n",
            "Test_loss: 9.239700312333692\n",
            "Weights: [-0.04107696  0.81430083 -0.17990705]\n",
            "--------------------------------\n",
            "Epoch: 341 / 500\n",
            "Train_loss: 13.180685133408236\n",
            "Test_loss: 9.239700310009248\n",
            "Weights: [-0.04107696  0.81430083 -0.17990705]\n",
            "--------------------------------\n",
            "Epoch: 342 / 500\n",
            "Train_loss: 13.180685133408236\n",
            "Test_loss: 9.239700307800023\n",
            "Weights: [-0.04107696  0.81430083 -0.17990705]\n",
            "--------------------------------\n",
            "Epoch: 343 / 500\n",
            "Train_loss: 13.180685133408234\n",
            "Test_loss: 9.239700305700309\n",
            "Weights: [-0.04107696  0.81430083 -0.17990705]\n",
            "--------------------------------\n",
            "Epoch: 344 / 500\n",
            "Train_loss: 13.180685133408234\n",
            "Test_loss: 9.239700303704678\n",
            "Weights: [-0.04107696  0.81430083 -0.17990705]\n",
            "--------------------------------\n",
            "Epoch: 345 / 500\n",
            "Train_loss: 13.180685133408234\n",
            "Test_loss: 9.23970030180797\n",
            "Weights: [-0.04107696  0.81430083 -0.17990705]\n",
            "--------------------------------\n",
            "Epoch: 346 / 500\n",
            "Train_loss: 13.18068513340823\n",
            "Test_loss: 9.23970030000528\n",
            "Weights: [-0.04107696  0.81430083 -0.17990705]\n",
            "--------------------------------\n",
            "Epoch: 347 / 500\n",
            "Train_loss: 13.18068513340823\n",
            "Test_loss: 9.239700298291948\n",
            "Weights: [-0.04107696  0.81430083 -0.17990705]\n",
            "--------------------------------\n",
            "Epoch: 348 / 500\n",
            "Train_loss: 13.18068513340823\n",
            "Test_loss: 9.239700296663548\n",
            "Weights: [-0.04107696  0.81430084 -0.17990705]\n",
            "--------------------------------\n",
            "Epoch: 349 / 500\n",
            "Train_loss: 13.180685133408229\n",
            "Test_loss: 9.239700295115867\n",
            "Weights: [-0.04107696  0.81430084 -0.17990705]\n",
            "--------------------------------\n",
            "Epoch: 350 / 500\n",
            "Train_loss: 13.18068513340823\n",
            "Test_loss: 9.239700293644898\n",
            "Weights: [-0.04107696  0.81430084 -0.17990705]\n",
            "--------------------------------\n",
            "Epoch: 351 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700292246852\n",
            "Weights: [-0.04107696  0.81430084 -0.17990705]\n",
            "--------------------------------\n",
            "Epoch: 352 / 500\n",
            "Train_loss: 13.18068513340823\n",
            "Test_loss: 9.239700290918103\n",
            "Weights: [-0.04107696  0.81430084 -0.17990705]\n",
            "--------------------------------\n",
            "Epoch: 353 / 500\n",
            "Train_loss: 13.180685133408229\n",
            "Test_loss: 9.239700289655218\n",
            "Weights: [-0.04107696  0.81430084 -0.17990705]\n",
            "--------------------------------\n",
            "Epoch: 354 / 500\n",
            "Train_loss: 13.18068513340823\n",
            "Test_loss: 9.239700288454937\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 355 / 500\n",
            "Train_loss: 13.180685133408229\n",
            "Test_loss: 9.239700287314154\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 356 / 500\n",
            "Train_loss: 13.180685133408229\n",
            "Test_loss: 9.239700286229914\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 357 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700285199424\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 358 / 500\n",
            "Train_loss: 13.180685133408229\n",
            "Test_loss: 9.239700284220016\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 359 / 500\n",
            "Train_loss: 13.18068513340823\n",
            "Test_loss: 9.239700283289153\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 360 / 500\n",
            "Train_loss: 13.180685133408229\n",
            "Test_loss: 9.23970028240443\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 361 / 500\n",
            "Train_loss: 13.180685133408229\n",
            "Test_loss: 9.239700281563568\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 362 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700280764383\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 363 / 500\n",
            "Train_loss: 13.180685133408229\n",
            "Test_loss: 9.239700280004822\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 364 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700279282903\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 365 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700278596771\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 366 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700277944657\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 367 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.23970027732486\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 368 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700276735789\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 369 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700276175915\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 370 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.2397002756438\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 371 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700275138055\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 372 / 500\n",
            "Train_loss: 13.180685133408229\n",
            "Test_loss: 9.239700274657386\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 373 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700274200539\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 374 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700273766339\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 375 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700273353662\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 376 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700272961443\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 377 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700272588664\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 378 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700272234366\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 379 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.23970027189763\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 380 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700271577584\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 381 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700271273398\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 382 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700270984295\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 383 / 500\n",
            "Train_loss: 13.180685133408229\n",
            "Test_loss: 9.239700270709523\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 384 / 500\n",
            "Train_loss: 13.180685133408229\n",
            "Test_loss: 9.239700270448376\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 385 / 500\n",
            "Train_loss: 13.180685133408224\n",
            "Test_loss: 9.239700270200169\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 386 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700269964263\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 387 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700269740055\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 388 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.23970026952696\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 389 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700269324425\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 390 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700269131934\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 391 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700268948983\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 392 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700268775103\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 393 / 500\n",
            "Train_loss: 13.180685133408229\n",
            "Test_loss: 9.239700268609838\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 394 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700268452768\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 395 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700268303483\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 396 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700268161597\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 397 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700268026745\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 398 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700267898577\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 399 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700267776765\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 400 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.23970026766099\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 401 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700267550953\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 402 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700267446366\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 403 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.23970026734697\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 404 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.2397002672525\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 405 / 500\n",
            "Train_loss: 13.180685133408229\n",
            "Test_loss: 9.239700267162709\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 406 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700267077373\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 407 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700266996264\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 408 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700266919177\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 409 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700266845912\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 410 / 500\n",
            "Train_loss: 13.180685133408229\n",
            "Test_loss: 9.23970026677628\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 411 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700266710097\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 412 / 500\n",
            "Train_loss: 13.180685133408224\n",
            "Test_loss: 9.239700266647196\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 413 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700266587409\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 414 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700266530592\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 415 / 500\n",
            "Train_loss: 13.180685133408229\n",
            "Test_loss: 9.23970026647659\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 416 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700266425263\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 417 / 500\n",
            "Train_loss: 13.180685133408229\n",
            "Test_loss: 9.23970026637648\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 418 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700266330114\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 419 / 500\n",
            "Train_loss: 13.180685133408229\n",
            "Test_loss: 9.239700266286048\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 420 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700266244167\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 421 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700266204363\n",
            "Weights: [-0.04107696  0.81430084 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 422 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700266166532\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 423 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700266130571\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 424 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700266096397\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 425 / 500\n",
            "Train_loss: 13.180685133408229\n",
            "Test_loss: 9.239700266063917\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 426 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700266033047\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 427 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700266003705\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 428 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.23970026597582\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 429 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700265949315\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 430 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700265924126\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 431 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700265900185\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 432 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.23970026587743\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 433 / 500\n",
            "Train_loss: 13.180685133408229\n",
            "Test_loss: 9.239700265855802\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 434 / 500\n",
            "Train_loss: 13.180685133408229\n",
            "Test_loss: 9.239700265835248\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 435 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700265815713\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 436 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700265797147\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 437 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700265779499\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 438 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700265762727\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 439 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700265746787\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 440 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700265731635\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 441 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700265717238\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 442 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700265703549\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 443 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700265690542\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 444 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.23970026567818\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 445 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700265666428\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 446 / 500\n",
            "Train_loss: 13.180685133408224\n",
            "Test_loss: 9.239700265655264\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 447 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.23970026564465\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 448 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700265634562\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 449 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700265624977\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 450 / 500\n",
            "Train_loss: 13.180685133408229\n",
            "Test_loss: 9.23970026561586\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 451 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.2397002656072\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 452 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.23970026559897\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 453 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700265591146\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 454 / 500\n",
            "Train_loss: 13.180685133408224\n",
            "Test_loss: 9.23970026558371\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 455 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700265576642\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 456 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700265569928\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 457 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700265563542\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 458 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700265557474\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 459 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700265551708\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 460 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700265546231\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 461 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700265541021\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 462 / 500\n",
            "Train_loss: 13.180685133408224\n",
            "Test_loss: 9.239700265536069\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 463 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700265531365\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 464 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700265526894\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 465 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.23970026552264\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 466 / 500\n",
            "Train_loss: 13.180685133408224\n",
            "Test_loss: 9.239700265518602\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 467 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.23970026551476\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 468 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700265511113\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 469 / 500\n",
            "Train_loss: 13.180685133408229\n",
            "Test_loss: 9.239700265507643\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 470 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700265504343\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 471 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700265501215\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 472 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700265498238\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 473 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700265495404\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 474 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700265492717\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 475 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700265490164\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 476 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700265487734\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 477 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700265485421\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 478 / 500\n",
            "Train_loss: 13.180685133408229\n",
            "Test_loss: 9.239700265483226\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 479 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700265481138\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 480 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700265479158\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 481 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700265477273\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 482 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700265475483\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 483 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700265473779\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 484 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700265472162\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 485 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700265470626\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 486 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700265469162\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 487 / 500\n",
            "Train_loss: 13.180685133408224\n",
            "Test_loss: 9.239700265467773\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 488 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700265466453\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 489 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700265465201\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 490 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700265464009\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 491 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700265462874\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 492 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700265461797\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 493 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700265460772\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 494 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700265459799\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 495 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700265458874\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 496 / 500\n",
            "Train_loss: 13.180685133408229\n",
            "Test_loss: 9.239700265457998\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 497 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.23970026545716\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 498 / 500\n",
            "Train_loss: 13.180685133408225\n",
            "Test_loss: 9.239700265456367\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 499 / 500\n",
            "Train_loss: 13.180685133408227\n",
            "Test_loss: 9.239700265455612\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n",
            "--------------------------------\n",
            "Epoch: 500 / 500\n",
            "Train_loss: 13.180685133408224\n",
            "Test_loss: 9.239700265454896\n",
            "Weights: [-0.04107696  0.81430085 -0.17990706]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "d0KhjoGBrQph",
        "outputId": "bfaf4cd1-b444-4658-81c8-5887d0f79046"
      },
      "source": [
        "plt.plot(log['train_loss'], label='Train Loss')\n",
        "plt.plot(log['test_loss'], label='Test Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3xV5Z3v8c9v750LSbgTLhI1qFiLCKFmQHGoCsfqaDtWxzpt1eIZ+/LYMyM6ndFq2+lYj87ROVNt1U6tnSpOa6utCrbS1iKC4qsWBEXkohUVa5BLiBIIt9x+54+1EjaYYCBZeydrfd+v137tvZ59Wc+D8Zsnv73Ws8zdERGR5EjluwMiIpJbCn4RkYRR8IuIJIyCX0QkYRT8IiIJk8l3B7pi2LBhXllZme9uiIj0KcuXL9/q7uUHtveJ4K+srGTZsmX57oaISJ9iZu901K5Sj4hIwij4RUQSRsEvIpIwfaLGLyLx0tTURE1NDXv27Ml3V2KhuLiYiooKCgoKuvR6Bb+I5FxNTQ39+/ensrISM8t3d/o0d6euro6amhrGjBnTpfeo1CMiObdnzx6GDh2q0O8BZsbQoUMP6a8nBb+I5IVCv+cc6r9lrIN/wdrN/OeidfnuhohIrxLr4H/2T7X86Lm38t0NEell6urqqKqqoqqqipEjRzJ69Oj27cbGxoO+d9myZcyaNeuQ9ldZWcnWrVu70+UeFesvd9Mpo7lVF5oRkf0NHTqUFStWAHDTTTdRVlbGP//zP7c/39zcTCbTcTxWV1dTXV2dk35GJdYz/kzKaG5R8IvIR7v88su56qqrmDJlCtdffz1Lly7l1FNPZdKkSUydOpXXX38dgEWLFvHpT38aCH5p/N3f/R1nnHEGxxxzDHfddVeX97d+/XqmT5/OhAkTmDFjBn/+858B+OUvf8n48eOZOHEin/zkJwFYvXo1kydPpqqqigkTJvDGG290a6yxnvFn0ilaNOMX6dW+/evVrHlve49+5rgjBvCvnznxkN9XU1PDH/7wB9LpNNu3b2fx4sVkMhmefvppvv71r/PYY4996D2vvfYaCxcuZMeOHXzsYx/jK1/5SpeOp7/66quZOXMmM2fO5P7772fWrFnMnTuXm2++maeeeorRo0ezbds2AO69916uueYaLrnkEhobG2lpaTnksWWLd/CnjObW1nx3Q0T6iM997nOk02kA6uvrmTlzJm+88QZmRlNTU4fvOe+88ygqKqKoqIjhw4ezefNmKioqPnJfL7zwAo8//jgAl112Gddffz0Ap512GpdffjkXX3wxF154IQCnnnoqt956KzU1NVx44YWMHTu2W+OMdfCnU0arQ2urk0rp0DGR3uhwZuZRKS0tbX/8L//yL5x55pnMmTOH9evXc8YZZ3T4nqKiovbH6XSa5ubmbvXh3nvvZcmSJcybN4+TTz6Z5cuX88UvfpEpU6Ywb948zj33XH74wx8yffr0w95HrGv8BelgePqCV0QOVX19PaNHjwZg9uzZPf75U6dO5eGHHwbgoYceYtq0aQC8+eabTJkyhZtvvpny8nLeffdd3nrrLY455hhmzZrF+eefz8qVK7u171gHfzqc5avOLyKH6vrrr+fGG29k0qRJ3Z7FA0yYMIGKigoqKir46le/yt13380DDzzAhAkT+MlPfsL3vvc9AK677jpOOukkxo8fz9SpU5k4cSK/+MUvGD9+PFVVVaxatYovfelL3eqLuff+UKyurvbDuRDLfy1+i1vmrWXlTZ9iQHHXFi8SkeitXbuWj3/84/nuRqx09G9qZsvd/UPHnsZ6xp9pm/HrkE4RkXaxDv60avwiIh8S6+Bvm/HrkE4RkX2SEfwq9YiItIt38Kd1VI+IyIEiC34zKzazpWb2ipmtNrNvh+2zzextM1sR3qqi6kM61VbjV6lHRKRNlGfu7gWmu3uDmRUAz5vZb8PnrnP3RyPcNwAF7TV+zfhFZJ+6ujpmzJgBwKZNm0in05SXlwOwdOlSCgsLD/r+RYsWUVhYyNSpUz/03OzZs1m2bBn33HNPz3e8h0QW/B6cINAQbhaEt5wmcFo1fhHpwEcty/xRFi1aRFlZWYfB3xdEWuM3s7SZrQC2APPdfUn41K1mttLM7jSzooN8RLe01fg14xeRj7J8+XJOP/10Tj75ZM4++2w2btwIwF133cW4ceOYMGECn//851m/fj333nsvd955J1VVVSxevLhLn3/HHXcwfvx4xo8fz3e/+10Adu7cyXnnncfEiRMZP348jzzyCAA33HBD+z4P5RdSV0W6SJu7twBVZjYImGNm44EbgU1AIXAf8DXg5gPfa2ZXAlcCHHXUUYe1/0xY429RjV+k9/rtDbDp1Z79zJEnwV/d1uWXuztXX301TzzxBOXl5TzyyCN84xvf4P777+e2227j7bffpqioiG3btjFo0CCuuuqqQ/orYfny5TzwwAMsWbIEd2fKlCmcfvrpvPXWWxxxxBHMmzcPCNYHqqurY86cObz22muYWfvSzD0pJ0f1uPs2YCFwjrtv9MBe4AFgcifvuc/dq929uq32dqjaDudsUqlHRA5i7969rFq1irPOOouqqipuueUWampqgGCNnUsuuYSf/vSnnV6V66M8//zzXHDBBZSWllJWVsaFF17I4sWLOemkk5g/fz5f+9rXWLx4MQMHDmTgwIEUFxdzxRVX8Pjjj1NSUtKTQwUinPGbWTnQ5O7bzKwfcBZwu5mNcveNFlwW/rPAqqj6oEXaRPqAQ5iZR8XdOfHEE3nhhRc+9Ny8efN47rnn+PWvf82tt97Kq6/23F8nxx9/PC+99BK/+c1v+OY3v8mMGTP41re+xdKlS1mwYAGPPvoo99xzD88880yP7ROinfGPAhaa2UrgRYIa/5PAQ2b2KvAqMAy4JaoOZLRkg4h0QVFREbW1te3B39TUxOrVq2ltbeXdd9/lzDPP5Pbbb6e+vp6Ghgb69+/Pjh07uvz506ZNY+7cuezatYudO3cyZ84cpk2bxnvvvUdJSQmXXnop1113HS+99BINDQ3U19dz7rnncuedd/LKK6/0+HijPKpnJTCpg/bDv3rAIdp35q5q/CLSuVQqxaOPPsqsWbOor6+nubmZa6+9luOPP55LL72U+vp63J1Zs2YxaNAgPvOZz3DRRRfxxBNPcPfdd7evpd9m9uzZzJ07t337j3/8I5dffjmTJweV7S9/+ctMmjSJp556iuuuu45UKkVBQQE/+MEP2LFjB+effz579uzB3bnjjjt6fLyxXpZ51YZ6Pn338/zwspM5+8SREfRMRA6HlmXueVqWOdR2BS7V+EVE9ol18Kfbj+pRqUdEpE2sgz+jo3pEeq2+UGbuKw713zLewa8zd0V6peLiYurq6hT+PcDdqauro7i4uMvvifTM3XxrO3NXa/WI9C4VFRXU1NRQW1ub767EQnFxMRUVFV1+fayDf98JXKrxi/QmBQUFjBkzJt/dSKxYl3oKVOoREfmQWAe/lmUWEfmwWAd/e41fM34RkXbxDv60avwiIgeKdfCnTcsyi4gcKNbBn0oZKdMJXCIi2WId/BAszawlG0RE9ol98BemUyr1iIhkiX3wF6SNZn25KyLSLgHBr1KPiEi2RAR/Y7NKPSIibWIf/IUZzfhFRLLFPvgzKVPwi4hkiX3wq8YvIrK/+Ad/Rodziohki33wF6ZV6hERyRb74FepR0Rkf4kI/kaVekRE2iUg+I2mZs34RUTaRBb8ZlZsZkvN7BUzW21m3w7bx5jZEjNbZ2aPmFlhVH0AlXpERA4U5Yx/LzDd3ScCVcA5ZnYKcDtwp7sfB3wAXBFhHyhIp3QFLhGRLJEFvwcaws2C8ObAdODRsP1B4LNR9QHalmzQjF9EpE2kNX4zS5vZCmALMB94E9jm7s3hS2qA0VH2oTCjwzlFRLJFGvzu3uLuVUAFMBk4oavvNbMrzWyZmS2rra097D6oxi8isr+cHNXj7tuAhcCpwCAzy4RPVQAbOnnPfe5e7e7V5eXlh73vTEpn7oqIZIvyqJ5yMxsUPu4HnAWsJfgFcFH4spnAE1H1AaAgYzRqxi8i0i7z0S85bKOAB80sTfAL5hfu/qSZrQEeNrNbgJeBH0fYBwrTKZoV/CIi7SILfndfCUzqoP0tgnp/ThSkU7Q6tLQ66ZTlarciIr1WAs7cDYaoL3hFRAIJCP5glq86v4hIIAHBH874dRKXiAiQpODXIZ0iIkAigj8o9ajGLyISiH3wF2aCIarGLyISiH3wF2XSAOxtUvCLiEASgr8gGOLe5pY890REpHeIf/Cn24JfM34REUhC8Iczfq3JLyISiH/wt9X4FfwiIkAigl81fhGRbAkIfh3VIyKSLfbBr+P4RUT2F/vgby/1NKnUIyICSQj+Ah3OKSKSLfbBX6jj+EVE9hP74M+kU2RSpqN6RERCsQ9+CL7g1QlcIiKBRAR/USalUo+ISCghwZ/WcfwiIqFkBH9BSjV+EZFQMoI/k9IJXCIioUQEf2EmpVKPiEgoEcFflEmzR6UeEREgIcFfXKAZv4hIm8iC38yONLOFZrbGzFab2TVh+01mtsHMVoS3c6PqQ5t+BWl2a60eEREAMhF+djPwT+7+kpn1B5ab2fzwuTvd/T8i3Pd+ihX8IiLtIgt+d98IbAwf7zCztcDoqPZ3MCWFafY0KvhFRCBHNX4zqwQmAUvCpn8ws5Vmdr+ZDY56/yr1iIjsE3nwm1kZ8BhwrbtvB34AHAtUEfxF8J1O3nelmS0zs2W1tbXd6kNxYZpdmvGLiAARB7+ZFRCE/kPu/jiAu2929xZ3bwV+BEzu6L3ufp+7V7t7dXl5ebf60a8gzd7mVlpbvVufIyISB1Ee1WPAj4G17n5HVvuorJddAKyKqg9t+hUE193VsfwiIl38ctfMSoHd7t5qZscDJwC/dfemg7ztNOAy4FUzWxG2fR34gplVAQ6sB/7X4Xa+q/oVBsG/u7GFksIoD2QSEen9upqCzwHTwi9ifw+8CPwtcElnb3D35wHr4KnfHGonu6ttxq8veEVEul7qMXffBVwI/Ke7fw44Mbpu9azsGb+ISNJ1OfjN7FSCGf68sC0dTZd6nmb8IiL7dDX4rwVuBOa4+2ozOwZYGF23elZ78GvGLyLStRq/uz8LPAtgZilgq7vPirJjPam4UDN+EZE2XZrxm9nPzGxAeHTPKmCNmV0Xbdd6TvvhnAp+EZEul3rGhWfdfhb4LTCG4FDNPqEknPHv3KvgFxHpavAXhGfhfhb4VXj8fp85Dba0KKho7WpsznNPRETyr6vB/0OCk61KgefM7Ghge1Sd6mllYfDv2KvgFxHp6pe7dwF3ZTW9Y2ZnRtOlnleUSZFOGTsV/CIiXf5yd6CZ3dG2WqaZfYdg9t8nmBmlhWnV+EVE6Hqp535gB3BxeNsOPBBVp6JQVpShQTN+EZEur9VzrLv/Tdb2t7MWXusTyoozKvWIiND1Gf9uM/vLtg0zOw3YHU2XolGqGb+ICND1Gf9VwH+b2cBw+wNgZjRdioZKPSIigS7N+N39FXefCEwAJrj7JGB6pD3rYaWFKvWIiMAhXoHL3beHZ/ACfDWC/kSmtCijo3pEROjepRc7ushKr1VWlFapR0SE7gV/n1myAaB/cQE79jTh3qe6LSLS4w765a6Z7aDjgDegXyQ9isiAfhlaHRr2NtO/uCDf3RERyZuDBr+7989VR6I2sF8Q9vW7mxT8IpJo3Sn19Cltwb99t+r8IpJsiQn+AVkzfhGRJEtM8A9U8IuIAAkK/gHFbaUeBb+IJFtign9giWb8IiKQoOAvK8yQMgW/iEhkwW9mR5rZQjNbY2arzeyasH2Imc03szfC+8FR9SFbKmUM7FfAtt2NudidiEivFeWMvxn4J3cfB5wC/L2ZjQNuABa4+1hgQbidE4NLC/lgp2b8IpJskQW/u29095fCxzuAtcBo4HzgwfBlDwKfjaoPBxpaWkjdzr252p2ISK+Ukxq/mVUCk4AlwAh33xg+tQkYEdmOX34InvzH9s2hpUXUNajUIyLJFnnwm1kZ8BhwbdaSzgB4sGJah6ummdmVbRd3r62tPbydb1oJqx5r3xxSVsj7OxX8IpJskQa/mRUQhP5D7v542LzZzEaFz48CtnT0Xne/z92r3b26vLz88DpQUAKNu9o3h5YW8sGuRlpbtUKniCRXlEf1GPBjYK2735H11K/Yd9nGmcATUfWBwhJobYLmYJY/tLSQVodtOqRTRBIsyhn/acBlwHQzWxHezgVuA84yszeA/xFuR6OgNLhv2gnAkLIiAOoa9AWviCRXVy+2fsjc/Xk6v0rXjKj2u5/CkuC+cRf0G8yI/kHwb9q+h7EjYrPitIjIIYn3mbvtM/6gzn/EoODaMRu37clXj0RE8i7ewV8YBn9jAwDDBwQz/vfqd+erRyIieRfz4M8q9QBFmTTDyoo04xeRRIt38B9Q6gE4YlCxZvwikmjxDv72GX9De9OogcVsrNeMX0SSK97BX7B/qQdg1MB+bNy2m+CkYRGR5Il38BeWBfcHlHp2NrawfY8uui4iyRTz4G+b8e9sbxo1MDykU3V+EUmoeAd/Jgj57OA/YlAxoGP5RSS54h38qVRQ7sn6crftJK6abZrxi0gyxTv4AYoGwN59q0GP6F9Mv4I0b9U2HORNIiLxlYDg7w979gV/KmUcN7yMdVsU/CKSTPEP/uIBsHfHfk1jR5TxxmYFv4gkU/yD/4BSD8DY4f3ZtH0P2/doXX4RSZ4EBP/+pR6AscOD4/tV7hGRJIp/8HdS6gFYp3KPiCRQ/IO/g1JPxeASijIp/rR5RydvEhGJr2QEf9MuaNm3REM6ZZwwsj+vbqjPY8dERPIj/sFfPCC4P2DW/4mjB/NKzTaaWlrz0CkRkfyJf/AXdRz81UcPYU9TK2ve297Bm0RE4iv+wd9vUHC/+4P9mj9xdNC+/J0PDnyHiEisJSD4hwT3u97fr3nUwH6MHtRPwS8iiRP/4C8Jg3/3hwO+unIwS96uo7VVF2URkeSIf/D36zz4p58wnK0Njayo2ZbjTomI5E8Cgj+s8R9Q6gE44/jhpFPGgrWbc9wpEZH8iX/wpwuCI3t2fzj4B5YU8BeVg3l6zZY8dExEJD8iC34zu9/MtpjZqqy2m8xsg5mtCG/nRrX//fQb3OGMH+CscSN5ffMO1m3RWbwikgxRzvhnA+d00H6nu1eFt99EuP99SoZ0OOMHOL/qCDIp45EX381JV0RE8i2y4Hf354CO0zbXSobBzq0dPjWsrIizxo3gsZc2sLe5JccdExHJvXzU+P/BzFaGpaDBOdlj2Qho6LyO//nJR/H+zkaefGVjTrojIpJPuQ7+HwDHAlXARuA7nb3QzK40s2Vmtqy2trZ7ey0bDju3QGvH6/JMO24YHx81gHsWrqNZa/eISMzlNPjdfbO7t7h7K/AjYPJBXnufu1e7e3V5eXn3dlw2AlqbOzyWH4Lr8F4zYyxvb93JnJc3dG9fIiK9XE6D38xGZW1eAKzq7LU9qmx4cN/Q+fH6nxo3golHDuL2371G/S5dklFE4ivKwzl/DrwAfMzMaszsCuDfzexVM1sJnAn8Y1T730/ZiOD+IMGfShn/dsF4PtjVxP+ZtyYn3RIRyYdMVB/s7l/ooPnHUe3voLoQ/AAnHjGQr5x+LPcsXMfkMUO4uPrIHHRORCS34n/mLsCAI4L7+pqPfOk/nnU8px03lG/OWcWzf+rml8oiIr1QMoK/sARKhnYp+NMp4z+/eDLHDS/jyv9exu9WbcpBB0VEcicZwQ8wsKJLwQ/BGj4/uWIyHx81gKt+upxb561hd6NO7hKReEhQ8B/Z5eAHGFpWxMNXnsIXpxzFjxa/zTnfe465L2/Qcf4i0uclKPgroP5d8K5fdKW4IM2/XXASP/vyFIoyKa59ZAVn/McivvP711nz3nZdwEVE+qTIjurpdQZXQmNDsGZP2aGdEDb1uGH87ppPMn/tZn7ywjt8f+E67n5mHYNLCpg8ZggnjBzAscPLOLa8lFED+zGoXwGplEUzDhGRbkpO8A89Lrh//81DDn4IjvM/+8SRnH3iSLZs38Ozf6plydvv8+L69/n9ms37/SGRThlDSwsZUlpISWGaksIM/QrT4eM0BekUKTPSKSOTMlJt92FbOnzcJush2b9O9m/v+PXZLPszO/kcEeldzho3gorBJT36mckJ/iHHBPd16+CoU7r1UcMHFPO56iP5XHic/56mFtbX7eSt2p1s3r6HrQ172bqjkfd3NbK7sYVdjc1sbdjL7qYWdjW20NzSSnOr09rqwb07La2OKkcicqAxw0oV/Idt0NGQygTB38OKC9KcMHIAJ4wc0K3P8fAXQHPWb4DsvyScztr3/4yO27M3Ov5MEel9Sgp7PqaTE/zpDAw7Hjb33uUYzIxM2sik890TEYmz5BzVAzCqCjauyHcvRETyKmHBPzFYr2eHzsYVkeRKXvADbHwlv/0QEcmjZAX/yPGAwXsq94hIciUr+Iv6B8fzq84vIgmWrOAHqPgL+PML0KpF10QkmZIX/MfNCK69u+GlfPdERCQvkhf8x04HS8G6+fnuiYhIXiQv+EuGwOiTYd3T+e6JiEheJC/4AcaeHZR6tr2b756IiORcMoN/wsXB/cs/zW8/RETyIJnBP/jooNb/8k90dI+IJE4ygx/g5Mth+wZY80S+eyIiklPJDf4TzoPh4+CZW6ClKd+9ERHJmeQGfyoNM74VXJHrxf/Kd29ERHImucEPcPw5cNxZ8PRNUPunfPdGRCQnIgt+M7vfzLaY2aqstiFmNt/M3gjvB0e1/y4xg/O/DwUl8MilsOv9vHZHRCQXopzxzwbOOaDtBmCBu48FFoTb+dV/BFz83/DB2/CzixX+IhJ7kQW/uz8HHJii5wMPho8fBD4b1f4PyZhpcNEDwTr9P/4UbFyZ7x6JiEQm1zX+Ee6+MXy8CRiR4/137uOfhsvmwt7t8KPpsOg22NuQ716JiPS4vH256+4OeGfPm9mVZrbMzJbV1tbmplOVp8H//iOM+2tY9H/hexPg2f+npR1EJFZyHfybzWwUQHi/pbMXuvt97l7t7tXl5eU56yAlQ+Ci++GKp4OLsy+8Bb57Ejz4GfjD3bDpVWhtzV1/RER6WCbH+/sVMBO4LbzvvafNHvkXcNnj8P7bsPIRWPU4/P6bwXOF/WHkSTBqApSfECwBMbgSBh4J6YK8dltE5KNYUHGJ4IPNfg6cAQwDNgP/CswFfgEcBbwDXOzuH3kYTXV1tS9btiySfh6S+g3w9rOwYXnwBfDmVdC0a9/zloKSoVAyDEqHQWl5sF3UH4rKoLDtVhpsF5RCujD4ZbHfffg4UxQ8TmWCQ09FRA6BmS139+oPtUcV/D2p1wT/gVpbYPt78MF62PYOfPAO7NwCO7eGt1rYtTX4kth7YDE4Sx3kZp0/h3Xwi8MOurlfw0e+N+LnRZLsM9+Fo6ce1ls7C/5cl3riJZWGQUcGN6Z1/jp3aN4LjQ3BbW8DNO6Epp3BOkEtjeGtg8fNjcEvDW/t5OYHeS7rNQf2Z/+Ggzzfnff2xPMiCVdY1uMfqeDPBTMoKA5upcPy3RsRSbhkr9UjIpJACn4RkYRR8IuIJIyCX0QkYRT8IiIJo+AXEUkYBb+ISMIo+EVEEqZPLNlgZrUEa/scjmHA1h7sTl+gMSeDxpwM3Rnz0e7+oeWN+0Twd4eZLetorYo405iTQWNOhijGrFKPiEjCKPhFRBImCcF/X747kAcaczJozMnQ42OOfY1fRET2l4QZv4iIZFHwi4gkTKyD38zOMbPXzWydmd2Q7/70FDO738y2mNmqrLYhZjbfzN4I7weH7WZmd4X/BivN7BP56/nhMbMjzWyhma0xs9Vmdk3YHtsxA5hZsZktNbNXwnF/O2wfY2ZLwvE9YmaFYXtRuL0ufL4yn/0/XGaWNrOXzezJcDvW4wUws/Vm9qqZrTCzZWFbZD/fsQ1+M0sD3wf+ChgHfMHMxuW3Vz1mNnDOAW03AAvcfSywINyGYPxjw9uVwA9y1Mee1Az8k7uPA04B/j78bxnnMQPsBaa7+0SgCjjHzE4BbgfudPfjgA+AK8LXXwF8ELbfGb6uL7oGWJu1HffxtjnT3auyjtmP7ufb3WN5A04FnsravhG4Md/96sHxVQKrsrZfB0aFj0cBr4ePfwh8oaPX9dUb8ARwVsLGXAK8BEwhOIszE7a3/5wDTwGnho8z4ess330/xHFWhCE3HXgSsDiPN2vc64FhB7RF9vMd2xk/MBp4N2u7JmyLqxHuvjF8vAkYET6O1b9D+Of8JGAJCRhzWPZYAWwB5gNvAtvcvTl8SfbY2scdPl8PDM1tj7vtu8D1QGu4PZR4j7eNA783s+VmdmXYFtnPty62HkPu7mYWu+N0zawMeAy41t23m1n7c3Eds7u3AFVmNgiYA5yQ5y5Fxsw+DWxx9+Vmdka++5Njf+nuG8xsODDfzF7LfrKnf77jPOPfAByZtV0RtsXVZjMbBRDebwnbY/HvYGYFBKH/kLs/HjbHeszZ3H0bsJCg1DHIzNombdljax93+PxAoC7HXe2O04C/NrP1wMME5Z7vEd/xtnP3DeH9FoJf8JOJ8Oc7zsH/IjA2PCKgEPg88Ks89ylKvwJmho9nEtTB29q/FB4JcApQn/XnY59gwdT+x8Bad78j66nYjhnAzMrDmT5m1o/ge421BL8ALgpfduC42/49LgKe8bAI3Be4+43uXuHulQT/vz7j7pcQ0/G2MbNSM+vf9hj4FLCKKH++8/2lRsRfmJwL/ImgLvqNfPenB8f1c2Aj0ERQ37uCoLa5AHgDeBoYEr7WCI5uehN4FajOd/8PY7x/SVADXQmsCG/nxnnM4TgmAC+H414FfCtsPwZYCqwDfgkUhe3F4fa68Plj8j2Gboz9DODJJIw3HN8r4W11W1ZF+fOtJRtERBImzqUeERHpgIJfRCRhFPwiIgmj4BcRSRgFv4hIwij4JdHMrCVcEbHt1mOruJpZpWWtoCrSW2jJBkm63e5ele9OiOSSZvwiHQjXR//3cI30pWZ2XNheaWbPhOugLzCzowU6IssAAAGMSURBVML2EWY2J1w7/xUzmxp+VNrMfhSup//78AxczGyWBdcXWGlmD+dpmJJQCn5Jun4HlHr+Nuu5enc/CbiHYNVIgLuBB919AvAQcFfYfhfwrAdr53+C4AxMCNZM/767nwhsA/4mbL8BmBR+zlVRDU6kIzpzVxLNzBrcvayD9vUEF0F5K1wgbpO7DzWzrQRrnzeF7RvdfZiZ1QIV7r436zMqgfkeXEgDM/saUODut5jZ74AGYC4w190bIh6qSDvN+EU65508PhR7sx63sO97tfMI1lv5BPBi1uqTIpFT8It07m+z7l8IH/+BYOVIgEuAxeHjBcBXoP3iKQM7+1AzSwFHuvtC4GsEywl/6K8OkaholiFJ1y+8wlWb37l72yGdg81sJcGs/Qth29XAA2Z2HVAL/M+w/RrgPjO7gmBm/xWCFVQ7kgZ+Gv5yMOAuD9bbF8kJ1fhFOhDW+KvdfWu++yLS01TqERFJGM34RUQSRjN+EZGEUfCLiCSMgl9EJGEU/CIiCaPgFxFJmP8P2CJyKW4wrdcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utIAUe6vMnpV"
      },
      "source": [
        "##2.3 Sklearn_Linear Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRK0kwWaBnEw",
        "outputId": "904367ee-7f8c-49e3-b68f-3c1268cbd760"
      },
      "source": [
        "from sklearn import datasets, linear_model\n",
        "# fit the model by Linear Regression\n",
        "regr = linear_model.LinearRegression(fit_intercept=False) # fit_intercept = False for calculating the bias\n",
        "regr.fit(X_train_bias, y_train)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHrSK7x2HgzO",
        "outputId": "345c70c2-c170-4525-809f-65587d95d97f"
      },
      "source": [
        "regr.coef_"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.04107696,  0.81430085, -0.17990706])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}